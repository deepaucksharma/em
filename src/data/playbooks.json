[
  {
    "id": "P-C6-1",
    "slug": "your-top-performer-gives-2-weeks-notice",
    "observableIds": [
      "C6-O3",
      "C6-O4"
    ],
    "capabilityIds": [
      "C6"
    ],
    "title": "Your Top Performer Gives 2 Weeks Notice",
    "context": "Your best senior engineer has an offer from a competitor. They seem decided but are giving you a courtesy conversation.",
    "topicsActivated": [
      "Team Health (Retention)",
      "Performance (Managing High Performers)",
      "Stakeholder Mgmt (Delivering Bad News)"
    ],
    "decisionFramework": "1. Listen: understand root cause (comp? growth? culture? manager?). 2. Assess: is this fixable? Be honest with yourself. 3. If fixable: make specific, genuine offer (not panicked counter). 4. If not fixable: wish them well, plan transition. 5. Inform your manager immediately. 6. Plan knowledge transfer. 7. Communicate to team. 8. Post-mortem: what could you have done differently?",
    "commonMistakes": "Panicked counter-offer that doesn't address root cause (buys 6 months at best). Guilt-tripping. Not telling your manager immediately. Not planning knowledge transfer. Ignoring the signal for the rest of the team.",
    "whatGoodLooksLike": "Root cause conversation within 24hrs. Honest assessment of fixability. If counter-offering: specific, addresses root cause, approved by leadership. If not: graceful exit with knowledge transfer plan. Team comms within 48hrs. Retrospective on retention practices. Industry reference: Netflix's Keeper Test philosophy frames retention honestly \u2014 if you wouldn't fight to keep them, help them leave well. Amazon separates comp levers from role/scope levers when constructing retention offers.",
    "mappingNotes": "Top performer retention scenario",
    "suggestedMetricIds": [
      "7.1",
      "7.2",
      "5.1"
    ]
  },
  {
    "id": "P-C8-1",
    "slug": "major-production-incident-during-your-vacation",
    "observableIds": [
      "C8-O1",
      "C8-O2",
      "C8-O4"
    ],
    "capabilityIds": [
      "C8"
    ],
    "title": "Major Production Incident During Your Vacation",
    "context": "You're on vacation. A Sev1 incident fires and your team is handling it. Your manager pings you asking for status.",
    "topicsActivated": [
      "Operational Risk (Incident Response)",
      "Team Health (Trust)",
      "Stakeholder Mgmt (Managing Up)"
    ],
    "decisionFramework": "1. Check: is the team handling it? If yes, trust them. 2. If team is struggling: provide guidance, don't take over. 3. Respond to manager with what you know. 4. Post-vacation: review incident response. 5. If team handled it well: celebrate. If not: identify gaps for training/process/runbooks.",
    "commonMistakes": "Taking over incident from vacation (undermines team, proves you haven't delegated). Going completely dark when your manager needs a response. Blaming team for not handling it perfectly. Using it as evidence that you can't take vacation.",
    "whatGoodLooksLike": "Team handles it using documented processes. You provide brief guidance if asked, but don't run the incident. Post-vacation retro focuses on process improvement, not blame. Your team proved they can function without you \u2014 that's a WIN. Industry reference: Google SRE's incident commander rotation ensures no single person is critical path. Amazon's COE (Correction of Error) process guarantees structural learning regardless of who runs the incident.",
    "mappingNotes": "Production incident during vacation",
    "suggestedMetricIds": [
      "1.3",
      "3.5",
      "3.3",
      "3.6"
    ]
  },
  {
    "id": "P-C5-1",
    "slug": "pm-wants-to-ship-a-feature-you-know-will-create-tech-debt",
    "observableIds": [
      "C5-O1",
      "C3-O4"
    ],
    "capabilityIds": [
      "C5",
      "C3"
    ],
    "title": "PM Wants to Ship a Feature You Know Will Create Tech Debt",
    "context": "PM has committed to a deadline with stakeholders. Meeting the deadline requires cutting corners that will cost the team months of debt later.",
    "topicsActivated": [
      "Cross-Functional Partnership (PM Disagreement)",
      "Decision Making (Trade-offs)",
      "Strategic Alignment (Trade-off Communication)"
    ],
    "decisionFramework": "1. Quantify the debt: specifically what gets cut, what's the future cost (hours, risk, incidents). 2. Present options: (A) Ship on time with known debt + remediation plan, (B) Extend deadline by X to do it right, (C) Reduce scope to hit deadline without debt. 3. Make trade-off PM's decision with full information. 4. If PM chooses debt: document the plan to pay it back. 5. Never: passive-aggressively build it 'right' and miss deadline.",
    "commonMistakes": "Just saying 'no' without alternatives. Passive compliance then complaining about tech debt later. Building it your way and missing the deadline. Not quantifying the actual cost of debt. Escalating without first trying to align directly with PM.",
    "whatGoodLooksLike": "You present 3 clear options with honest trade-offs. PM makes an informed decision. If debt is accepted: remediation plan is written, capacity allocated, and PM agrees to the payback timeline. No resentment \u2014 it was a joint decision with eyes open. Industry reference: Amazon's 6-pager format forces explicit trade-off documentation before any investment decision, preventing the 'we didn't know the cost' problem. Stripe's writing culture similarly requires architectural trade-offs to be written, not just discussed.",
    "mappingNotes": "PM tech debt conflict",
    "suggestedMetricIds": [
      "8.6",
      "8.4",
      "1.2"
    ]
  },
  {
    "id": "P-C12-1",
    "slug": "two-of-your-engineers-are-in-conflict",
    "observableIds": [
      "C12-O1",
      "C12-O2"
    ],
    "capabilityIds": [
      "C12"
    ],
    "title": "Two of Your Engineers Are in Conflict",
    "context": "Two senior engineers disagree on a technical approach. It's gotten personal \u2014 code reviews are hostile, standup is tense, team morale is affected.",
    "topicsActivated": [
      "Team Health (Constructive Conflict, Psych Safety)",
      "Performance (Feedback)",
      "Engineering Culture (Inclusive Environment)"
    ],
    "decisionFramework": "1. Talk to each privately: understand their perspective and concerns. 2. Separate the technical from the personal. 3. Resolve the technical disagreement: use RFC process, get external reviewer, make a decision. 4. Address the personal: specific feedback to each on behavior (not opinions). 5. Mediated conversation if needed. 6. Clear expectations going forward. 7. Follow up in 2 weeks.",
    "commonMistakes": "Ignoring it ('they'll work it out'). Taking sides publicly. Making it about who's right technically while ignoring interpersonal damage. Punishing both equally. Moving one to another team without addressing the root cause.",
    "whatGoodLooksLike": "Technical decision made through structured process (not by who argues louder). Both engineers receive specific, private feedback on behavior. Both acknowledge the impact on the team. Clear working agreement going forward. Follow-up confirms improvement. Team morale recovers. Industry reference: Microsoft's Model-Coach-Care framework gives managers a structured approach for coaching through interpersonal conflict without taking sides. Google's Project Aristotle research shows that how teams handle conflict is a key differentiator of effective teams.",
    "mappingNotes": "Engineer conflict resolution",
    "suggestedMetricIds": [
      "7.9",
      "5.1",
      "7.8"
    ]
  },
  {
    "id": "P-C1-1",
    "slug": "you-inherit-a-low-performing-team",
    "observableIds": [
      "C1-O8",
      "C1-O7",
      "C6-O2"
    ],
    "capabilityIds": [
      "C1",
      "C6"
    ],
    "title": "You Inherit a Low-Performing Team",
    "context": "You join as EM. In your first month you discover: 2 engineers should probably be on a PIP, the team's metrics are worst in the org, morale is low, and the previous EM left because of burnout.",
    "topicsActivated": [
      "First 90 Days (Assessment, Credibility)",
      "Performance (Underperformance, PIPs)",
      "Team Health (Psych Safety)",
      "Stakeholder Mgmt (Managing Up)"
    ],
    "decisionFramework": "1. Month 1: Listen and assess. Build trust. Understand WHY performance is low (people? process? scope? leadership?). 2. Month 2: Quick wins (fix one obvious pain point). Start 1:1 cadence. Begin addressing most critical performance gap. 3. Month 3: Comprehensive plan to leadership \u2014 honest assessment + proposed path. Begin formal performance processes where needed. 4. Communicate to team: 'here's what I've observed, here's what we're going to change, here's how I'll support you.'",
    "commonMistakes": "Making changes in week 1 before understanding context. Putting people on PIP immediately (you weren't there, you don't have evidence yet). Blaming previous EM publicly. Promising everything will be better without a plan. Sugar-coating the situation to leadership.",
    "whatGoodLooksLike": "Honest assessment to leadership at 30 days (with plan, not just problems). Trust built through listening and quick wins. Performance conversations started with clear expectations and genuine support. Team feels heard and sees a path forward. Measurable improvement at 90 days. Industry reference: Amazon's Leadership Principles give new EMs a shared language for diagnosing team problems (e.g., 'Dive Deep,' 'Insist on the Highest Standards'). Meta's structured onboarding model accelerates new hire effectiveness through immersive ramp-up programs with clear milestones.",
    "mappingNotes": "Inherit low-performing team",
    "suggestedMetricIds": [
      "5.1",
      "7.1",
      "7.9",
      "1.2",
      "1.4"
    ]
  },
  {
    "id": "P-C1-2",
    "slug": "layoffs-are-coming-and-you-know-before-your-team",
    "observableIds": [
      "C1-O4",
      "C7-O3"
    ],
    "capabilityIds": [
      "C1",
      "C7"
    ],
    "title": "Layoffs Are Coming and You Know Before Your Team",
    "context": "Your Director told you confidentially: 20% RIF next week. You know who's affected on your team. You can't tell anyone yet.",
    "topicsActivated": [
      "Team Health (Leading Through Layoffs)",
      "Stakeholder Mgmt (Managing Up)",
      "Engineering Culture (Trust)"
    ],
    "decisionFramework": "1. Prepare: talking points for affected and remaining team members. 2. Coordinate: logistics (access revocation, equipment, benefits information). 3. Day of: tell affected people first, in private, with humanity. 4. Same day: address remaining team honestly. 5. Following weeks: over-communicate stability, re-plan roadmap, address survivor guilt. 6. Don't pretend nothing happened.",
    "commonMistakes": "Leaking the news early. Being cold or scripted with affected people. Not being available for remaining team. Immediately jumping to 'let's focus on the work' without acknowledging grief. Not re-planning the roadmap (pretending you can do the same work with fewer people).",
    "whatGoodLooksLike": "Affected people treated with dignity and respect \u2014 they remember how they were treated. Remaining team hears honesty: what happened, what's changing, what's not. Roadmap re-planned publicly (team sees you're realistic). 1:1s with every remaining team member within 1 week. Zero additional voluntary attrition in following quarter. Industry reference: Netflix's radical transparency culture means layoff communication is direct and humane. Amazon's 'disagree and commit' principle applies \u2014 once the decision is made, execute with compassion and clarity.",
    "mappingNotes": "Layoffs incoming \u2014 pre-disclosure",
    "suggestedMetricIds": [
      "7.1",
      "5.1",
      "7.9"
    ]
  },
  {
    "id": "P-C5-2",
    "slug": "your-new-vp-wants-to-change-everything",
    "observableIds": [
      "C5-O10",
      "C1-O4"
    ],
    "capabilityIds": [
      "C5",
      "C1"
    ],
    "title": "Your New VP Wants to Change Everything",
    "context": "New VP joins. They want to re-org, change tech stack, adopt new processes, and reset all roadmaps. Your team is anxious.",
    "topicsActivated": [
      "Team Health (New Leadership, Managing Through Adversity)",
      "Stakeholder Mgmt (Managing Up)",
      "Strategic Alignment (Planning)"
    ],
    "decisionFramework": "1. Listen to VP's vision \u2014 understand the intent behind changes. 2. Identify: which changes are reasonable? Which are destructive? 3. Push back constructively on changes that would hurt (with data). 4. Shield team from unnecessary churn while supporting legitimate changes. 5. Communicate to team: what's changing, what's not, what you're advocating for. 6. Build trust with new VP through early results.",
    "commonMistakes": "Immediately complying with everything (your team suffers). Immediately resisting everything (you get replaced). Badmouthing the VP to your team. Letting team anxiety fester without addressing it. Not adapting at all to new leadership's style.",
    "whatGoodLooksLike": "You earn VP's trust by delivering results on their priorities. You protect your team from unnecessary churn. Changes that happen are well-communicated and well-executed. Team sees you as their advocate who also adapts to new reality. Six months later: VP trusts you, team trusts you, things are stable. Industry reference: Amazon's Working Backwards process gives new leaders a structured way to propose changes (PR/FAQ format), which channels 'change everything' energy into evidence-based proposals.",
    "mappingNotes": "New VP changes everything",
    "suggestedMetricIds": [
      "1.2",
      "3.5",
      "5.1",
      "8.4"
    ]
  },
  {
    "id": "P-C6-2",
    "slug": "you-discover-a-senior-engineer-is-quietly-job-searching",
    "observableIds": [
      "C6-O3",
      "C6-O4"
    ],
    "capabilityIds": [
      "C6"
    ],
    "title": "You Discover a Senior Engineer Is Quietly Job Searching",
    "context": "Through the grapevine (or obvious calendar gaps), you realize one of your senior engineers is interviewing elsewhere. They haven't told you.",
    "topicsActivated": [
      "Team Health (Flight Risk, Stay Interviews)",
      "Performance (Managing High Performers, Career Conversations)"
    ],
    "decisionFramework": "1. Don't confront them about job searching (it's their right). 2. Create opportunity for honest career conversation: 'How are you feeling about your growth here? What would make the next year exciting for you?' 3. Listen for the underlying need. 4. If you can address it: propose specific changes (scope, comp, growth path). 5. If you can't: be honest about constraints. 6. Either way: plan for potential departure (knowledge transfer, succession).",
    "commonMistakes": "Confronting them directly about interviewing (violation of trust). Panic counter-offer out of nowhere. Ignoring the signals hoping they'll stay. Punishing them with reduced access or scope. Telling their teammates.",
    "whatGoodLooksLike": "Proactive career conversation that feels natural, not surveillance-triggered. You address underlying needs (if possible) before an offer forces your hand. If they stay: because root cause was addressed. If they leave: you had time to plan. Either way: trust preserved. Industry reference: Netflix proactively conducts 'stay interviews' with key talent rather than waiting for exit signals. Google's manager effectiveness research shows that career development conversations are the #1 retention driver.",
    "mappingNotes": "Senior engineer quietly job searching",
    "suggestedMetricIds": [
      "7.1",
      "5.1",
      "7.8"
    ]
  },
  {
    "id": "P-C3-1",
    "slug": "your-team-needs-to-deliver-a-critical-migration-under-tight-deadline",
    "observableIds": [
      "C3-O6",
      "C4-O2"
    ],
    "capabilityIds": [
      "C3",
      "C4"
    ],
    "title": "Your Team Needs to Deliver a Critical Migration Under Tight Deadline",
    "context": "Leadership committed to migrating off a legacy system in Q3. Your team owns it. The deadline is real (vendor contract expiration). Scope is larger than estimated.",
    "topicsActivated": [
      "Technical Strategy (Migration Strategy)",
      "Engineering Excellence (Delivery Practices)",
      "Stakeholder Mgmt (Trade-off Communication, Delivering Bad News)",
      "Team Health (Capacity Planning)"
    ],
    "decisionFramework": "1. Re-estimate honestly: what's actually required? What's the gap vs. plan? 2. Present options: (A) Full migration by deadline with X% overtime risk, (B) Phased migration \u2014 critical paths by deadline, remaining by Q4, (C) Full migration with additional resources. 3. Communicate gap EARLY \u2014 don't wait until deadline is missed. 4. If proceeding under pressure: protect team health (no sustained overtime), cut scope aggressively, track weekly.",
    "commonMistakes": "Hiding the gap ('we'll figure it out'). Asking team to work overtime for months. Promising delivery you know isn't realistic. Not flagging the risk until it's a crisis. Blaming the estimate instead of managing the situation.",
    "whatGoodLooksLike": "Risk flagged at earliest moment with clear options. Leadership makes informed trade-off decision. Team executes with realistic scope and sustainable pace. Weekly progress visible to stakeholders. If phased: phase 1 delivered on deadline, clear plan for phase 2. Team emerges without burnout. Industry reference: Amazon's 'escalation is not failure' culture means timeline risks are surfaced weekly in business reviews. Google's design doc culture ensures migration scope is documented and reviewed before execution begins.",
    "mappingNotes": "Critical migration under deadline",
    "suggestedMetricIds": [
      "1.2",
      "1.4",
      "2.5",
      "3.5"
    ]
  },
  {
    "id": "P-C14-1",
    "slug": "calibration-committee-wants-to-downgrade-your-engineers-rating",
    "observableIds": [
      "C14-O2",
      "C14-O3"
    ],
    "capabilityIds": [
      "C14"
    ],
    "title": "Calibration Committee Wants to Downgrade Your Engineer's Rating",
    "context": "You submitted 'Exceeds Expectations' for a strong senior engineer. In calibration, peer managers are pushing for 'Meets' based on cross-team comparison. You disagree.",
    "topicsActivated": [
      "Performance (Calibration Preparation, Ratings Distribution)",
      "Stakeholder Mgmt (Influence Without Authority)"
    ],
    "decisionFramework": "1. Present evidence calmly: specific impact examples, peer feedback, cross-team comparison data you prepared. 2. Listen to counter-arguments: is there a valid point you're missing? 3. If your case is strong: hold firm with evidence. 4. If their case has merit: gracefully accept and adjust. 5. Either way: communicate outcome to your engineer honestly. 6. Never: throw the committee under the bus.",
    "commonMistakes": "Caving without defending your case. Getting emotional or combative. Not preparing comparison data in advance. Telling your engineer 'I fought for you but they overruled me' (blames the system, undermines trust in the process). Inflating evidence to win the argument.",
    "whatGoodLooksLike": "Strong, evidence-based case that even skeptics find credible. If you win: earned through preparation, not politics. If you lose: you understand why and can explain it honestly to your engineer. Your credibility in the room is intact or strengthened regardless of outcome. Industry reference: Google's promo committee model makes calibration evidence-based against published rubrics \u2014 managers present cases, an independent committee decides, reducing bias from any single manager.",
    "mappingNotes": "Calibration downgrade fight",
    "suggestedMetricIds": [
      "5.1",
      "7.8"
    ]
  },
  {
    "id": "P-C1-3",
    "slug": "a-cross-team-initiative-is-stalled-because-no-one-owns-it",
    "observableIds": [
      "C1-O2",
      "C5-O7"
    ],
    "capabilityIds": [
      "C1",
      "C5"
    ],
    "title": "A Cross-Team Initiative Is Stalled Because No One Owns It",
    "context": "An important cross-org project has been discussed for months but nobody is driving it. Multiple teams would benefit but each expects the other to lead.",
    "topicsActivated": [
      "Cross-Functional (Dependency Negotiation)",
      "Stakeholder Mgmt (Driving Alignment, Political Capital)",
      "Decision Making (First Principles)"
    ],
    "decisionFramework": "1. Assess: should your team own this? (Impact on your goals, capacity, strategic value) 2. If yes: volunteer to drive. Write a proposal with scope, timeline, resource needs. 3. Get buy-in from other teams (pre-wire 1:1). 4. Establish DACI. 5. Drive to completion with regular cross-team syncs. 6. If no: identify who should own it and facilitate that conversation.",
    "commonMistakes": "Waiting for someone else to step up (it's been months \u2014 they won't). Volunteering without capacity (good intentions, failed execution). Trying to drive without explicit buy-in from participating teams. Not getting DACI clear upfront.",
    "whatGoodLooksLike": "You either own it and drive it to completion, or you facilitate someone else owning it. Cross-team initiative ships. Your role is visible to leadership. Political capital built through execution, not just volunteering. 'Drove [initiative] across [X] teams, delivering [Y] outcome.' Industry reference: Amazon's single-threaded leadership model assigns one clear owner to every cross-team initiative. The DACI framework (Driver, Approver, Contributors, Informed), widely adopted at companies like Google and Intuit, prevents the 'everyone contributes, nobody drives' stall.",
    "mappingNotes": "Stalled cross-team initiative",
    "suggestedMetricIds": [
      "2.6",
      "1.2",
      "8.1"
    ]
  },
  {
    "id": "P-C14-2",
    "slug": "your-manager-asks-you-to-rate-everyone-meets-expectations",
    "observableIds": [
      "C14-O3",
      "C14-O4"
    ],
    "capabilityIds": [
      "C14"
    ],
    "title": "Your Manager Asks You to Rate Everyone 'Meets Expectations'",
    "context": "Your Director says the org needs to compress ratings this cycle. They want fewer 'Exceeds' ratings. You have 3 engineers who genuinely exceeded.",
    "topicsActivated": [
      "Performance (Ratings Distribution, Delivering Feedback)",
      "Stakeholder Mgmt (Managing Up)",
      "Decision Making (First Principles)"
    ],
    "decisionFramework": "1. Understand the constraint: is this a hard mandate or guidance? What's driving it? 2. Present your strongest case: 'I can compress 2 of the 3, but this one engineer delivered [X] \u2014 here's the evidence.' 3. If Director insists across the board: push back with data one more time, clearly. 4. If overruled: you own the outcome \u2014 deliver feedback honestly to your engineers. 5. Never: blame your Director to your team.",
    "commonMistakes": "Silently complying and giving unfair ratings. Openly fighting your Director in calibration (burning political capital). Telling your engineers 'I wanted to give you Exceeds but my boss said no.' Distributing the pain randomly instead of based on evidence.",
    "whatGoodLooksLike": "You advocate clearly with evidence. You compress where reasonable and hold firm where it matters most. If compromised: you deliver honest feedback to affected engineers ('here's what you accomplished, here's the context for the rating, here's your growth path'). Trust preserved in both directions. Industry reference: Google's calibration committees include managers from outside the immediate org to prevent local rating compression. Netflix skips forced distributions entirely, trusting managers to differentiate honestly.",
    "mappingNotes": "Forced ratings compression",
    "suggestedMetricIds": [
      "7.1",
      "7.9",
      "5.1"
    ]
  },
  {
    "id": "P-C11-1",
    "slug": "you-need-to-build-a-new-team-from-scratch",
    "observableIds": [
      "C11-O1",
      "C11-O2",
      "C11-O4"
    ],
    "capabilityIds": [
      "C11"
    ],
    "title": "You Need to Build a New Team From Scratch",
    "context": "You've been given headcount to build a new team for a greenfield project. You have 6 months to hire 6 engineers and deliver first milestone.",
    "topicsActivated": [
      "Talent Acquisition (Hiring Loops, Bar, Onboarding)",
      "Org Design (Team Structure)",
      "Technical Strategy (Vision)",
      "Team Health (First 90 Days)"
    ],
    "decisionFramework": "1. First: define team mission, scope, and technical vision (BEFORE hiring). 2. Hire tech lead first (partner on architecture and subsequent hiring). 3. Hiring loop: calibrated, structured, bar raiser. Don't lower bar for speed. 4. Onboard in waves (don't hire all 6 simultaneously). 5. Establish team charter, principles, and rituals from day 1. 6. First milestone should be deliberately achievable \u2014 team needs an early win.",
    "commonMistakes": "Hiring all 6 simultaneously (onboarding chaos). Not defining technical direction before hiring (building a team without a mission). Hiring fast at the expense of quality. Not establishing culture intentionally (letting it happen by accident). Setting unrealistic first milestone.",
    "whatGoodLooksLike": "Tech lead hired in month 1, contributing to architecture and hiring. Engineers hired in waves of 2, each wave onboarded before next. Team charter established early. First milestone delivered on time \u2014 team has confidence and momentum. By month 6: functioning, cohesive team with clear identity. Industry reference: Amazon's 'two-pizza team' principle with single-threaded leadership provides a proven template for new team formation. Meta's structured onboarding program gets new engineers productive within 6 weeks through mentorship pairing and progressive ramp-up milestones.",
    "mappingNotes": "Build team from scratch",
    "suggestedMetricIds": [
      "7.3",
      "7.4",
      "7.5"
    ]
  },
  {
    "id": "P-C6-3",
    "slug": "one-of-your-ems-is-struggling-director-scenario",
    "observableIds": [
      "C6-O6",
      "C6-O7"
    ],
    "capabilityIds": [
      "C6"
    ],
    "title": "One of Your EMs Is Struggling (Director Scenario)",
    "context": "One of your EMs is underperforming: their team's metrics are declining, skip-level feedback is concerning, and the EM seems overwhelmed.",
    "topicsActivated": [
      "Managing Managers (Coaching EMs, Skip-Levels)",
      "Performance (Underperformance)",
      "Team Health (First 90 Days for the EM's team)"
    ],
    "decisionFramework": "1. Diagnose: is this a skill gap, will gap, or situation gap? (Can't do it, won't do it, or set up to fail?) 2. If skill: invest in coaching \u2014 specific development plan with milestones. 3. If will: direct conversation about expectations and fit. 4. If situation: fix the situation (scope, support, resources). 5. Increase 1:1 cadence. 6. Set clear improvement timeline (60-90 days). 7. If no improvement: you need to make a change.",
    "commonMistakes": "Ignoring it hoping they'll figure it out. Taking over their EM responsibilities (they'll never develop). Replacing them without genuine coaching attempt. Not protecting their team during the transition. Waiting too long to act (the team suffers).",
    "whatGoodLooksLike": "Honest diagnosis shared with EM. Specific coaching plan with clear milestones. Increased support (not micromanagement). If they improve: great \u2014 you developed a manager. If not: managed transition with dignity, team protected, replacement plan ready. Industry reference: Microsoft's Model-Coach-Care framework provides a diagnostic lens \u2014 is this a skill gap (coach), will gap (direct conversation), or situation gap (fix the environment)? Amazon measures Directors on how independently their EMs operate.",
    "mappingNotes": "Struggling EM (Director scenario)",
    "suggestedMetricIds": [
      "5.1",
      "7.1",
      "7.9",
      "1.2"
    ]
  },
  {
    "id": "P-C8-2",
    "slug": "production-outage-caused-by-your-teams-deploy",
    "observableIds": [
      "C8-O1",
      "C8-O4"
    ],
    "capabilityIds": [
      "C8"
    ],
    "title": "Production Outage Caused by Your Team's Deploy",
    "context": "Your team deployed a change that caused a major production incident. Customers are affected. Leadership is asking what happened.",
    "topicsActivated": [
      "Operational Risk (Incident Response, Post-Mortems)",
      "Stakeholder Mgmt (Delivering Bad News, Status Communication)",
      "Engineering Excellence (Release Management, Testing)"
    ],
    "decisionFramework": "1. First: resolve the incident (rollback, mitigation). 2. Communicate: status updates to stakeholders every 30min during incident. 3. Take ownership immediately with leadership: 'our deploy caused this, here's what we're doing.' 4. Post-incident: blameless post-mortem within 48hrs. 5. Action items with owners and deadlines. 6. Prevention: what process/test/check would have caught this? 7. Communicate lessons learned broadly.",
    "commonMistakes": "Pointing fingers at the engineer who deployed. Hiding or minimizing the impact. Not communicating status during the incident. Post-mortem that's actually a blame session. Promising 'it won't happen again' without systemic changes.",
    "whatGoodLooksLike": "Incident resolved quickly through documented process. Ownership taken immediately and clearly. Blameless post-mortem produces systemic improvements (not 'be more careful'). Action items completed within 2 weeks. Similar class of incident prevented going forward. Team trust preserved. Industry reference: Google's blameless post-mortem template requires systemic root causes and rejects 'human error' as an acceptable finding. Amazon's COE process ensures action items have owners, deadlines, and executive visibility.",
    "mappingNotes": "Outage caused by your deploy",
    "suggestedMetricIds": [
      "1.4",
      "1.3",
      "3.3",
      "3.5"
    ]
  },
  {
    "id": "P-C5-3",
    "slug": "youre-asked-to-take-on-scope-that-doesnt-fit-your-team",
    "observableIds": [
      "C5-O3",
      "C2-O2"
    ],
    "capabilityIds": [
      "C5",
      "C2"
    ],
    "title": "You're Asked to Take on Scope That Doesn't Fit Your Team",
    "context": "Your VP wants your team to own a new area that doesn't align with your team's expertise or mission. It's a political hot potato nobody else wants.",
    "topicsActivated": [
      "Org Design (Cognitive Load, Single-Threaded Ownership)",
      "Stakeholder Mgmt (Managing Up, Framing Asks)",
      "Decision Making (Saying No, Trade-offs)"
    ],
    "decisionFramework": "1. Understand the real ask: why your team? What's the actual need? 2. Assess honestly: can your team absorb this without degrading current work? What's the cost? 3. If no: propose alternatives (which team should own this? new team needed?). 4. If yes with conditions: 'we can take this if we deprioritize X or get Y headcount.' 5. Never: silently absorb scope that will crush your team.",
    "commonMistakes": "Accepting without understanding the cost. Declining without offering alternatives. Complaining to your team about leadership decisions. Absorbing it and burning out your team to prove you can handle it.",
    "whatGoodLooksLike": "Clear-eyed assessment presented to VP: 'here's what this would cost us' with specific trade-offs. If you accept: explicit agreement on what you're deprioritizing or what resources you're getting. If you decline: alternative proposal that solves the VP's actual problem. Either way: you're seen as thoughtful and solutions-oriented. Industry reference: Amazon's 'two-pizza team' cognitive load principle provides a framework for saying no to scope expansion \u2014 teams should own what they can cognitively manage, not what politics assigns.",
    "mappingNotes": "Asked to take misfit scope",
    "suggestedMetricIds": [
      "8.4",
      "2.5",
      "2.6"
    ]
  },
  {
    "id": "P-C5-4",
    "slug": "a-key-platform-dependency-is-unreliable-and-the-platform-team-wont-prioritize-fixes",
    "observableIds": [
      "C5-O3",
      "C5-O4"
    ],
    "capabilityIds": [
      "C5"
    ],
    "title": "A Key Platform Dependency Is Unreliable and the Platform Team Won't Prioritize Fixes",
    "context": "Your team's reliability is suffering because of an upstream platform dependency. The platform team acknowledges the issue but has higher priorities.",
    "topicsActivated": [
      "Cross-Functional (Dependency Negotiation, Platform Partnership)",
      "Technical Strategy (Dependency Management)",
      "Operational Risk (Dependency Risk)"
    ],
    "decisionFramework": "1. Quantify impact: how many incidents? Customer impact? Eng hours spent on workarounds? 2. Build relationship with platform EM (understand their constraints). 3. Propose mutual solutions: can you contribute a fix? Can you implement a fallback? 4. If blocked: escalate with data to Director level. 5. Parallel: build resilience against this dependency (circuit breakers, fallbacks, caching).",
    "commonMistakes": "Complaining without data. Escalating without first trying direct partnership. Building a competing solution in secret. Blaming the platform team publicly. Doing nothing and accepting the pain.",
    "whatGoodLooksLike": "Data-driven conversation with platform team. Mutual problem-solving \u2014 maybe you contribute the fix, they review and merge. Fallback strategy implemented regardless. If escalation needed: both EMs present jointly to leadership with shared facts and proposed solution. Relationship preserved. Industry reference: Google's SRE model defines explicit SLOs and error budgets for platform dependencies, giving consuming teams concrete data for escalation. Amazon's service ownership model means every dependency has a named owner.",
    "mappingNotes": "Unreliable platform dependency",
    "suggestedMetricIds": [
      "3.5",
      "3.3",
      "1.2"
    ]
  },
  {
    "id": "P-C12-2",
    "slug": "your-team-has-zero-diversity-and-youre-told-to-fix-it",
    "observableIds": [
      "C12-O5",
      "C11-O3"
    ],
    "capabilityIds": [
      "C12",
      "C11"
    ],
    "title": "Your Team Has Zero Diversity and You're Told to Fix It",
    "context": "HR/leadership points out your team is homogeneous. You're asked to 'improve diversity' in your next hires.",
    "topicsActivated": [
      "Talent Acquisition (Sourcing, Hiring Loops)",
      "Engineering Culture (Inclusive Environment)",
      "Decision Making (First Principles)"
    ],
    "decisionFramework": "1. Audit the full pipeline: where are candidates dropping off? (Sourcing? Screen? Onsite? Offer?) 2. Fix the pipeline, not the outcome: diverse sourcing channels, structured interviews with rubrics, diverse interview panels, bias training. 3. Fix retention too: is your team environment actually inclusive? Would diverse hires thrive? 4. Never: lower the bar or hire for optics. 5. This is a sustained effort, not a one-quarter initiative.",
    "commonMistakes": "Token hiring (one diverse hire into unwelcoming environment \u2014 they leave). Lowering the bar (insulting and counterproductive). Treating it as a checkbox exercise. Only fixing sourcing without fixing culture. Delegating entirely to recruiting team.",
    "whatGoodLooksLike": "Pipeline audited and fixed at each stage. Interview process restructured to reduce bias (structured rubrics, diverse panels). Culture assessed honestly \u2014 are diverse voices actually heard? Sustained effort over multiple quarters. Diversity improves AND inclusion improves AND bar maintained. Industry reference: Meta's structured hiring rubrics evaluate demonstrated competencies (not 'culture fit'), and interview panels are deliberately diverse. Google's hiring committees review for bias patterns across interview cycles.",
    "mappingNotes": "Zero diversity fix mandate",
    "suggestedMetricIds": [
      "7.7",
      "5.1",
      "7.4"
    ]
  },
  {
    "id": "P-C7-1",
    "slug": "you-strongly-disagree-with-a-decision-made-above-you",
    "observableIds": [
      "C7-O1",
      "C7-O7"
    ],
    "capabilityIds": [
      "C7"
    ],
    "title": "You Strongly Disagree with a Decision Made Above You",
    "context": "Your Director/VP made a strategic decision you think is wrong. It directly affects your team's direction.",
    "topicsActivated": [
      "Stakeholder Mgmt (Managing Up)",
      "Decision Making (Reversible vs Irreversible, First Principles)",
      "Team Health (Trust)"
    ],
    "decisionFramework": "1. Understand the full context (you might not have it). Ask questions, not accusations. 2. If you still disagree after understanding context: make your case once, clearly, with data. 3. If overruled: disagree and commit. Execute fully. 4. Never: undermine the decision through passive resistance or complaining to your team. 5. If the decision fails: don't say 'I told you so.' Help fix it.",
    "commonMistakes": "Going along silently (your perspective was valuable and you withheld it). Fighting the same battle repeatedly after the decision is made. Telling your team 'I disagree but we have to do it' (undermines the decision and your leadership above). Sabotaging through half-hearted execution.",
    "whatGoodLooksLike": "You made your case clearly and respectfully. After the decision: you commit fully and execute as if it were your own idea. Your team sees you supporting the direction. If the decision proves wrong: you help course-correct without blame. Your Director remembers you raised the concern constructively. Industry reference: Amazon's 'disagree and commit' principle provides a cultural framework: voice dissent clearly with data, then execute fully once the decision is made. Netflix's culture memo explicitly states that 'silence is agreement.'",
    "mappingNotes": "Disagree with decision above you",
    "suggestedMetricIds": [
      "8.1",
      "8.2",
      "8.4"
    ]
  },
  {
    "id": "P-C5-5",
    "slug": "youre-preparing-for-your-own-promotion-to-director",
    "observableIds": [
      "C5-O5",
      "C5-O6",
      "C14-O2"
    ],
    "capabilityIds": [
      "C5",
      "C14"
    ],
    "title": "You're Preparing for Your Own Promotion to Director",
    "context": "You've been a strong EM for 2+ years and want to make the jump to Director. What do you actually need to demonstrate?",
    "topicsActivated": [
      "Performance (Promo Packets, Career Growth)",
      "Stakeholder Mgmt (Sponsor Relationships, Executive Communication)",
      "Managing Managers (all principles)",
      "Org Design (all principles)"
    ],
    "decisionFramework": "1. Map current scope to Director-level rubric \u2014 identify gaps honestly. 2. Build evidence of Director-level work: cross-team impact, org-level strategy, developing other managers. 3. Get a sponsor (not just a mentor) at VP+ level. 4. Demonstrate you can operate at Director altitude while still delivering as EM. 5. Your promo case should be obvious before you submit it.",
    "commonMistakes": "Asking for the title without doing the job. Focusing on managing your team well (necessary but not sufficient \u2014 Directors operate across teams). Not building sponsor relationships. Waiting for your manager to nominate you instead of driving your own career. Neglecting your current team while chasing Director scope.",
    "whatGoodLooksLike": "You've been operating at Director level for 6+ months before the promo discussion. Cross-team impact is documented. You've developed at least one future EM. You have a sponsor who advocates for you. Your current team continues to thrive. The promo feels like recognition of reality, not aspiration. Industry reference: Google's promo committee model evaluates cross-team impact and leadership scope, not just team management. Amazon expects Director candidates to demonstrate 'Hire and Develop the Best' through their EMs' independence.",
    "mappingNotes": "Preparing own Director promotion",
    "suggestedMetricIds": [
      "1.2",
      "3.5",
      "7.1",
      "8.4",
      "8.2"
    ]
  },
  {
    "id": "P-C9-1",
    "slug": "dora-metrics-show-decline-but-team-feels-fine",
    "observableIds": [
      "C9-O1",
      "C9-O3"
    ],
    "capabilityIds": [
      "C9"
    ],
    "title": "DORA Metrics Show Decline But Team Feels Fine",
    "context": "Your DORA metrics have been trending down for 2 quarters \u2014 deploy frequency dropped 40%, lead time increased 3x. But team morale is fine and nobody is complaining. Your VP saw the dashboard and is asking questions.",
    "topicsActivated": [
      "Metrics Measurement (DORA analysis)",
      "Activity Metrics (diagnostic vs punitive)",
      "Stakeholder Mgmt (framing to VP)"
    ],
    "decisionFramework": "1. Investigate root cause: is it real degradation or measurement artifact (team grew, monolith split, deploy definition changed)? 2. Correlate with outcomes: are incidents up? Is velocity actually down? Customer impact? 3. If real: identify bottleneck (CI pipeline? review queue? test suite? environment contention?). 4. If artifact: fix the measurement, communicate context to VP. 5. Either way: present findings with context, not just numbers. 6. Create improvement plan with team ownership, not top-down targets.",
    "commonMistakes": "Setting DORA targets as team KPIs (Goodhart's Law). Gaming deploy frequency by splitting deploys. Presenting raw numbers to VP without context. Blaming the team instead of investigating systemic causes. Ignoring the signal because \"team feels fine.\"",
    "whatGoodLooksLike": "Root cause identified within 1 week. VP gets context-rich update (not just \"we'll fix it\"). If real: targeted improvement with measurable progress within 1 quarter. If artifact: measurement corrected, team educated on what metrics actually mean. Metrics used as shared investigation tool, never punishment. Industry reference: Google's DORA team recommends investigating metrics as diagnostic signals, not setting them as performance targets. Microsoft's SPACE framework pairs behavioral metrics (DORA) with perceptual metrics (developer satisfaction) to avoid tunnel vision.",
    "mappingNotes": "DORA decline investigation scenario \u2014 metrics as diagnostic",
    "suggestedMetricIds": [
      "1.2",
      "1.4",
      "1.1",
      "5.1",
      "2.5"
    ]
  },
  {
    "id": "P-C10-1",
    "slug": "budget-cut-lose-20-headcount-keep-critical-deliverables",
    "observableIds": [
      "C10-O1",
      "C10-O2",
      "C10-O5"
    ],
    "capabilityIds": [
      "C10"
    ],
    "title": "Budget Cut: Lose 20% Headcount, Keep Critical Deliverables",
    "context": "Company announces 20% headcount reduction. You have 25 engineers across 4 teams. You need to identify 5 positions to cut while maintaining delivery on your top-3 commitments. You have 2 weeks before the announcement.",
    "topicsActivated": [
      "Resource Allocation (headcount planning)",
      "Strategic Prioritization (ruthless triage)",
      "People Management (layoff execution)",
      "Stakeholder Mgmt (managing up during crisis)"
    ],
    "decisionFramework": "1. Map all current work to business impact tiers: critical (revenue/compliance), important (strategic), nice-to-have (quality-of-life). 2. Identify what STOPS \u2014 be explicit, write it down. 3. Assess team composition: performance, criticality of knowledge, single points of failure. 4. Optimize for org survival: protect critical path, maintain minimum viable team per area. 5. Prepare talking points for affected individuals (with your HR partner). 6. Tell affected people FIRST, with humanity. 7. Re-plan roadmap with remaining team within 1 week. 8. Communicate revised plan to stakeholders within 2 weeks.",
    "commonMistakes": "Spreading cuts evenly across teams (peanut butter approach). Cutting based solely on performance ratings. Not communicating what stops. Protecting pet projects over business-critical work. Delaying the conversation with affected people. Not re-planning the roadmap after cuts.",
    "whatGoodLooksLike": "Clear-eyed impact analysis delivered to leadership within days. Affected individuals told with dignity and support. Remaining team has revised, achievable roadmap within 1 week. Stakeholders know what's changing. Zero regrettable attrition from survivors. Team productive within 3-4 weeks. Industry reference: Netflix prioritizes density of talent over headcount \u2014 fewer, stronger engineers over more warm bodies. Amazon's resource allocation process forces explicit Tier 1/2/3 prioritization during budget constraints.",
    "mappingNotes": "Headcount reduction scenario \u2014 resource allocation under constraint",
    "suggestedMetricIds": [
      "8.4",
      "8.2",
      "7.1",
      "1.2"
    ]
  },
  {
    "id": "P-C13-1",
    "slug": "security-audit-finding-critical-vulnerability-in-production",
    "observableIds": [
      "C13-O1",
      "C13-O2",
      "C13-O4"
    ],
    "capabilityIds": [
      "C13"
    ],
    "title": "Security Audit Finding: Critical Vulnerability in Production",
    "context": "Internal security audit found a critical vulnerability (e.g., unencrypted PII in logs, open S3 bucket, SQL injection vector) in your team's production service. Security team has given you a 72-hour remediation window. Your team is mid-sprint on a high-priority feature launch.",
    "topicsActivated": [
      "Security Compliance (vulnerability SLAs)",
      "Operational Risk (incident-adjacent)",
      "Stakeholder Mgmt (communicating priority shift)",
      "Strategic Prioritization (competing demands)"
    ],
    "decisionFramework": "1. Assess severity and blast radius immediately \u2014 what data is exposed, who is affected, what's the regulatory implication? 2. Communicate to your manager and stakeholders SAME DAY: feature timeline is shifting. 3. Assign your best engineer to the fix \u2014 this is not junior work. 4. Implement fix + write regression test + add to automated scanning to prevent recurrence. 5. Document root cause: how did this get to production? What process failed? 6. Close the loop with security team within SLA. 7. Post-fix: update threat model, add to security review checklist, share learning broadly.",
    "commonMistakes": "Treating it as security team's problem. Trying to fix it quietly without telling stakeholders about the feature delay. Assigning it to whoever is \"free\" instead of your most capable engineer. Fixing the symptom without addressing how it got to production. Not communicating the feature timeline impact upward.",
    "whatGoodLooksLike": "Vulnerability patched within 72hrs. Root cause documented. Process gap identified and closed (new automated check, updated review checklist). Stakeholders informed proactively about feature delay. Security team relationship strengthened, not adversarial. Team learns from it \u2014 similar vulnerability never recurs. Industry reference: Google's zero-day response model uses pre-defined severity tiers with SLA-based response timelines. Amazon's mandatory security review process ensures vulnerabilities are caught before launch, not after audit.",
    "mappingNotes": "Critical security finding response scenario",
    "suggestedMetricIds": [
      "9.1",
      "9.3",
      "9.2"
    ]
  },
  {
    "id": "P-C3-2",
    "slug": "your-teams-tech-stack-becomes-deprecated-company-wide",
    "observableIds": [
      "C3-O4",
      "C3-O6"
    ],
    "capabilityIds": [
      "C3"
    ],
    "title": "Your Team's Tech Stack Becomes Deprecated Company-Wide",
    "context": "Platform team announces your primary framework/language is sunset. Migration timeline is 18 months. You have 100K lines of code in the deprecated stack, active feature development in flight, and no one on your team has deep experience with the target stack.",
    "topicsActivated": [
      "Technical Strategy (Migration Planning, Tech Debt)",
      "Team Health (Skill Development, Morale)",
      "Stakeholder Mgmt (Timeline Negotiation)",
      "Engineering Excellence (Incremental Migration)"
    ],
    "decisionFramework": "1. Assess blast radius: how much of your codebase is affected? What's the dependency graph? Which services are most critical? 2. Evaluate team readiness: who has experience with the target stack? What training is needed? Budget learning time explicitly. 3. Negotiate timeline: 18 months may be unrealistic for 100K LOC \u2014 present data-driven counter-proposal if needed. 4. Choose migration strategy: strangler fig (incremental) vs. big bang rewrite. Almost always choose strangler fig. 5. Create migration backlog: prioritize by risk (most critical services first) and coupling (least coupled first for early wins). 6. Run feature development and migration in parallel \u2014 do NOT freeze features for 18 months. 7. Establish migration metrics: % migrated, velocity per sprint, blockers. Report weekly to platform team and leadership. 8. Negotiate for dedicated migration capacity (at least 30% of team bandwidth).",
    "commonMistakes": "Attempting a big-bang rewrite (historically fails at 100K+ LOC scale). Freezing all feature work to focus on migration (business won't tolerate it). Not investing in team upskilling early (migration stalls in month 3 when nobody knows the new stack). Treating migration as purely technical without communicating business impact upward. Waiting until month 12 to flag that the timeline is unrealistic. Not negotiating for dedicated capacity \u2014 trying to squeeze migration into 'spare time.'",
    "whatGoodLooksLike": "Strangler fig migration plan published within 2 weeks of announcement. Team upskilling started immediately (pairing sessions, training budget, internal tech talks). First service migrated within 6 weeks as proof of concept. Feature development continues at 70% capacity during migration. Weekly migration metrics visible to all stakeholders. Timeline renegotiated early if needed \u2014 with data, not excuses. Team emerges with new skills and stronger architecture. Zero production incidents caused by the migration itself. Industry reference: Google's internal migrations use the strangler fig pattern (coined by Martin Fowler) combined with design doc culture to provide a proven framework for large-scale stack transitions. Amazon tracks migration completion as a first-class program metric in weekly business reviews.",
    "mappingNotes": "Tech stack deprecation and large-scale migration planning",
    "suggestedMetricIds": [
      "8.4",
      "8.6",
      "1.2",
      "3.5"
    ]
  },
  {
    "id": "P-C1-4",
    "slug": "merging-two-teams-after-acquisition-re-org",
    "observableIds": [
      "C1-O3",
      "C1-O14"
    ],
    "capabilityIds": [
      "C1"
    ],
    "title": "Merging Two Teams After Acquisition/Re-org",
    "context": "Company acquired a startup. You're responsible for merging their 8-person team with your 12-person team. Different tech stacks (they use Python/Django, you use Java/Spring), different cultures (startup speed vs. enterprise process), different processes (they have no sprint planning, you run 2-week sprints with full ceremonies). Some role overlap exists. Both teams are anxious about who stays, who leads, and what changes.",
    "topicsActivated": [
      "Org Design (Team Mergers, Culture Integration)",
      "Team Health (Psychological Safety, Trust Building)",
      "Technical Strategy (Stack Consolidation)",
      "Stakeholder Mgmt (Managing Up, Managing Expectations)"
    ],
    "decisionFramework": "1. Week 1: Meet every person on the acquired team individually \u2014 understand their role, concerns, what they value about their current culture. Listen more than you talk. 2. Week 2: Identify overlaps and complementary skills. Map who owns what. Do NOT make org changes yet. 3. Weeks 3-4: Establish shared rituals \u2014 joint standup, shared Slack channel, cross-team pairing sessions. Let cultures cross-pollinate before forcing convergence. 4. Month 2: Make org structure decisions \u2014 be transparent about rationale. If roles overlap, decide based on skill and contribution, not 'which team they came from.' 5. Month 2-3: Consolidate processes gradually \u2014 take the best of both. Don't force the acquired team to adopt all your processes wholesale. 6. Months 3-6: Tech stack convergence plan \u2014 decide on target stack with input from both teams. This is a multi-quarter effort. 7. Throughout: over-communicate. Ambiguity breeds anxiety and attrition.",
    "commonMistakes": "Treating the acquired team as subordinate ('you're joining us, adopt our ways'). Making org changes in week 1 before understanding the people. Forcing immediate tech stack convergence (creates resentment and risk). Ignoring cultural differences and expecting instant alignment. Losing key acquired talent because they feel undervalued. Not addressing role overlap directly \u2014 letting it fester into political infighting. Assuming your processes are better because you're the acquirer.",
    "whatGoodLooksLike": "Every acquired team member feels heard within the first 2 weeks. Org structure decisions made transparently with clear rationale. Best practices adopted from BOTH teams (acquired team sees their ideas valued). Zero regrettable attrition from either team in the first 6 months. Shared team identity emerges organically. Tech stack convergence plan is data-driven and has buy-in from engineers on both sides. By month 6: it's one team, not 'us and them.' Industry reference: Spotify's Squad model demonstrates that teams can maintain identity and autonomy even through organizational changes. Meta's structured onboarding ensures acquired engineers integrate through progressive immersion with mentorship pairing rather than forced assimilation.",
    "mappingNotes": "Post-acquisition team merger and cultural integration",
    "suggestedMetricIds": [
      "1.2",
      "5.1",
      "7.1",
      "2.5"
    ]
  },
  {
    "id": "P-C8-3",
    "slug": "managing-through-a-major-security-incident-data-breach",
    "observableIds": [
      "C8-O1",
      "C8-O2",
      "C13-O1",
      "C13-O2"
    ],
    "capabilityIds": [
      "C8",
      "C13"
    ],
    "title": "Managing Through a Major Security Incident (Data Breach)",
    "context": "Security team discovers unauthorized data access to your team's service. Customer PII (names, emails, hashed passwords) may be compromised. The scope is unclear \u2014 could be hundreds or millions of records. Legal, PR, and the exec team are involved. Your team owns the affected service. The incident is already escalated to the CEO. Clock is ticking on regulatory notification requirements (72 hours under GDPR).",
    "topicsActivated": [
      "Operational Risk (Incident Command, War Room)",
      "Security Compliance (Breach Response, Regulatory Notification)",
      "Stakeholder Mgmt (Exec Communication, Cross-Functional Coordination)",
      "Team Health (Crisis Management, Protecting Engineers)"
    ],
    "decisionFramework": "1. Immediate (Hour 0-4): Establish incident command structure. Your role is EM-level incident commander for the technical response. Contain the breach \u2014 revoke compromised credentials, patch the vulnerability, preserve forensic evidence (do NOT destroy logs). 2. Hour 4-12: Scope the impact \u2014 how many records, what data types, what time period. Work with security team on forensic analysis. Provide regular updates to exec war room (every 2 hours). 3. Hour 12-48: Support legal team with technical facts for regulatory notification. Prepare customer-facing technical explanation (work with PR). Continue forensic analysis \u2014 understand attack vector completely. 4. Day 2-7: Implement permanent fix (not just patch). Conduct thorough security review of adjacent systems. Begin post-incident review. 5. Week 2-4: Full post-mortem with systemic improvements. Security architecture review. Team well-being check \u2014 breaches are extremely stressful. 6. Throughout: protect your engineers from exec pressure. They need to focus on the technical response, not fielding questions from 15 VPs.",
    "commonMistakes": "Destroying evidence in the rush to fix (deleting logs, wiping servers). Downplaying severity to leadership ('it's probably not that bad'). Letting every executive directly ping your engineers for status. Not involving legal immediately (regulatory clock is ticking). Promising a root cause before forensics are complete. Blaming the engineer who wrote the vulnerable code. Not checking on your team's well-being during and after the crisis. Treating the post-mortem as optional because 'we already fixed it.'",
    "whatGoodLooksLike": "Breach contained within hours, not days. Forensic evidence preserved from minute one. Exec team gets regular, honest updates (not optimistic guesses). Legal has what they need for regulatory notification within 72 hours. Customer communication is transparent and accurate. Root cause identified and systemic fix implemented (not just a patch). Security review of adjacent systems completed. Post-mortem produces architectural improvements that prevent this class of vulnerability. Your team is recognized for their response, not blamed for the breach. No one burns out from the crisis. Industry reference: Google's BeyondCorp zero-trust model and incident response framework provide a mature template for breach containment. Amazon's security incident response requires forensic evidence preservation from minute one.",
    "mappingNotes": "Major security incident and data breach response",
    "suggestedMetricIds": [
      "9.1",
      "9.3",
      "1.3",
      "3.5"
    ]
  },
  {
    "id": "P-C6-4",
    "slug": "your-skip-level-reports-are-unhappy-with-their-em",
    "observableIds": [
      "C6-O6",
      "C6-O11"
    ],
    "capabilityIds": [
      "C6"
    ],
    "title": "Your Skip-Level Reports Are Unhappy With Their EM",
    "context": "In skip-level 1:1s, multiple engineers (3 out of 7) express frustration with their EM. Recurring themes: lack of career development conversations, micromanagement on technical decisions, poor communication about team priorities, and feeling unheard. The EM has been in role for 18 months and was promoted from within. Their self-assessment is that things are going well.",
    "topicsActivated": [
      "Managing Managers (Skip-Level Feedback, Coaching EMs)",
      "Performance (Underperformance, Feedback Delivery)",
      "Team Health (Psychological Safety, Trust)"
    ],
    "decisionFramework": "1. Validate the signal: are 3 engineers saying the same thing independently, or is this a clique? Are the themes consistent? Is there performance data that corroborates (retention risk, engagement survey scores, velocity trends)? 2. Do NOT relay skip-level feedback verbatim to the EM \u2014 that destroys skip-level trust. Instead, synthesize themes: 'I'm hearing signals that career development and communication could be stronger on your team.' 3. Have a direct coaching conversation with the EM: share observed themes (not attributing to specific people), ask for their perspective, listen for self-awareness. 4. Co-create a development plan: specific actions on career conversations (monthly with each report), delegation framework (decide which technical decisions they truly need to own vs. delegate), communication cadence (weekly team priorities update). 5. Set a 60-day checkpoint. Increase your own 1:1 cadence with this EM to weekly. 6. Follow up with skip-level reports in 30 and 60 days \u2014 is it improving? 7. If no improvement after 60 days with genuine coaching: this may be a performance conversation, not a coaching conversation.",
    "commonMistakes": "Sharing skip-level feedback directly with attribution ('Alex said you're micromanaging') \u2014 destroys skip-level trust permanently. Ignoring the signal because the EM's self-assessment is positive. Taking over the EM's responsibilities instead of coaching them. Moving engineers to other teams without addressing the root cause (the EM's behavior). Giving vague feedback ('you need to communicate better') without specific, actionable guidance. Waiting too long \u2014 3 unhappy engineers become 5, then attrition starts.",
    "whatGoodLooksLike": "EM receives synthesized, actionable feedback without knowing who said what. Development plan has specific, measurable actions (not 'be better at communication'). EM shows genuine self-awareness and desire to improve. Skip-level reports notice improvement within 30-60 days. If EM improves: you developed a manager and built trust in both directions. If EM doesn't improve: you have documented pattern and can make a fair decision. Either way: skip-level reports trust that their feedback was heard and acted upon. Industry reference: Google's manager effectiveness survey provides anonymous, structured feedback that Directors can use to identify coaching gaps without burning skip-level trust. Microsoft's 'Connects' continuous feedback model catches issues before they become patterns.",
    "mappingNotes": "Skip-level dissatisfaction with EM \u2014 coaching and intervention",
    "suggestedMetricIds": [
      "5.1",
      "7.8",
      "7.1"
    ]
  },
  {
    "id": "P-C10-2",
    "slug": "budget-is-frozen-but-commitments-remain",
    "observableIds": [
      "C10-O2",
      "C10-O5",
      "C2-O2"
    ],
    "capabilityIds": [
      "C10",
      "C2"
    ],
    "title": "Budget Is Frozen But Commitments Remain",
    "context": "Mid-year budget freeze announced. No new hires (you had 4 open reqs), no new vendor contracts, limited travel and conference budget. But your Q3-Q4 commitments haven't been adjusted. Leadership expects delivery on the original roadmap. Your team is already at capacity, and two of the open reqs were for a critical new initiative that starts next quarter.",
    "topicsActivated": [
      "Resource Allocation (Constraint-Based Planning)",
      "Strategic Prioritization (Ruthless Triage)",
      "Stakeholder Mgmt (Managing Up, Resetting Expectations)",
      "Delivery Management (Doing More With Less)"
    ],
    "decisionFramework": "1. Immediate: map every commitment to required capacity (people-weeks). Total it up. Compare to available capacity without the 4 missing hires. Quantify the gap precisely (e.g., 'we're 35% short of committed capacity'). 2. Tier your commitments: Tier 1 (must deliver \u2014 revenue, contractual, compliance), Tier 2 (should deliver \u2014 strategic, high-value), Tier 3 (could deliver \u2014 quality-of-life, nice-to-have). 3. Present the gap to leadership with options: (A) Cut Tier 3 entirely and reduce Tier 2 scope \u2014 deliver Tier 1 on time. (B) Delay Tier 2 to Q1 next year \u2014 deliver Tier 1 + reduced Tier 3. (C) Deliver everything with explicit quality/reliability trade-offs (not recommended). 4. Force the prioritization decision upward \u2014 do not silently absorb an impossible scope. 5. Communicate to team: 'here's what changed, here's what we're focusing on, here's what we're NOT doing.' 6. Explore creative solutions: internal transfers, contractor budget (if not frozen), automation of manual work, scope reduction on individual projects.",
    "commonMistakes": "Silently accepting the original commitments and burning out your team trying to deliver. Not quantifying the capacity gap with data (just saying 'we can't do it all'). Spreading the team thin across everything instead of cutting scope decisively. Waiting until Q3 delivery misses to raise the alarm. Not exploring creative alternatives (internal mobility, automation, scope negotiation). Complaining to your team about leadership instead of actively managing upward.",
    "whatGoodLooksLike": "Capacity gap quantified and presented to leadership within 1 week of freeze announcement. Prioritization framework forces explicit trade-off decisions at the leadership level. Team has a clear, achievable plan \u2014 they know what they're doing and what they're NOT doing. Creative alternatives explored and implemented where possible. Tier 1 commitments delivered on time. Leadership sees you as someone who manages constraints proactively, not someone who either over-promises or just complains. Team morale stays stable because expectations are realistic. Industry reference: Netflix's 'highly aligned, loosely coupled' model lets teams self-prioritize within strategic constraints during budget freezes. Amazon's weekly business reviews force explicit scope-to-capacity matching when resources contract.",
    "mappingNotes": "Budget freeze with unchanged commitments \u2014 constraint-based planning",
    "suggestedMetricIds": [
      "8.4",
      "8.3",
      "2.5",
      "1.2"
    ]
  },
  {
    "id": "P-C10-3",
    "slug": "leading-a-cost-optimization-initiative-finops",
    "observableIds": [
      "C10-O3",
      "C3-O9"
    ],
    "capabilityIds": [
      "C10",
      "C3"
    ],
    "title": "Leading a Cost Optimization Initiative (FinOps)",
    "context": "CFO mandates 30% cloud cost reduction across engineering. You're asked to lead the initiative for your org (4 teams, ~40 engineers). Current monthly spend is $2M across AWS services. No one has a clear picture of what's driving costs. Teams have never been held accountable for infrastructure spend. Finance wants a plan in 2 weeks and results within the quarter.",
    "topicsActivated": [
      "Financial Management (Cloud Cost Optimization, FinOps)",
      "Technical Strategy (Infrastructure Efficiency)",
      "Cross-Functional Partnership (Finance/Engineering Alignment)",
      "Stakeholder Mgmt (Driving Org-Wide Initiative)"
    ],
    "decisionFramework": "1. Week 1 \u2014 Visibility: Get cost breakdown by team, service, and environment. Tag everything. Identify top 10 cost drivers (usually 80/20 rule applies \u2014 a few services drive most spend). Distinguish production from non-production costs. 2. Week 2 \u2014 Quick wins: Identify low-hanging fruit (unused resources, oversized instances, non-prod environments running 24/7, unattached EBS volumes, idle load balancers). These often yield 10-15% savings with minimal effort. 3. Week 2 \u2014 Plan: Present tiered savings plan: Tier 1 (quick wins, 10-15%, 2 weeks), Tier 2 (right-sizing and reserved instances, 10-15%, 6-8 weeks), Tier 3 (architectural changes \u2014 caching, serverless migration, data tiering, 5-10%, 1-2 quarters). 4. Execution: Assign cost owners per team. Create cost dashboards visible to all engineers. Set up weekly cost review cadence. Implement automated alerts for spend anomalies. 5. Sustainability: Bake cost awareness into architecture reviews and PR reviews. Make cloud cost a standing item in team retrospectives. Celebrate wins publicly. 6. Report to CFO monthly with progress against target, broken down by initiative.",
    "commonMistakes": "Promising 30% savings purely from quick wins (architectural changes are needed for the last 10-15%). Not tagging resources properly (you can't optimize what you can't measure). Making engineers feel punished for using cloud resources (kills innovation). Cutting non-prod environments that teams actually need for testing. Not setting up sustainable practices (costs creep back within 6 months). Treating it as a one-time project instead of an ongoing discipline. Over-optimizing and causing production reliability issues (saving $50K/month but causing outages that cost more).",
    "whatGoodLooksLike": "Full cost visibility achieved within 2 weeks. Quick wins (10-15%) delivered within first month. 30% target achieved within the quarter through combination of quick wins, right-sizing, and architectural improvements. Cost dashboards used by engineers proactively (not just finance). FinOps practices embedded in team culture \u2014 cost is considered in architecture decisions going forward. No production reliability degradation. CFO sees engineering as a partner in financial discipline, not a cost center to be squeezed. Industry reference: Amazon's FinOps practice requires every team to track cost-per-transaction and present monthly cost attribution. Google Cloud's internal cost allocation model tags every resource to a team and product, making waste visible.",
    "mappingNotes": "Cloud cost optimization and FinOps leadership",
    "suggestedMetricIds": [
      "10.1",
      "10.2",
      "8.4"
    ]
  },
  {
    "id": "P-C11-2",
    "slug": "managing-through-a-hiring-freeze",
    "observableIds": [
      "C11-O1",
      "C11-O5",
      "C6-O4"
    ],
    "capabilityIds": [
      "C11",
      "C6"
    ],
    "title": "Managing Through a Hiring Freeze",
    "context": "6-month hiring freeze announced company-wide. You have 3 open reqs mid-pipeline \u2014 one candidate just passed the onsite, another is in final round, and a third is at phone screen stage. Your team of 9 is already stretched across 3 projects. Two senior engineers are showing signs of burnout. One mid-level engineer recently mentioned they've been getting recruiter outreach. Attrition risk is real and you can't backfill.",
    "topicsActivated": [
      "Talent Acquisition (Pipeline Management During Freeze)",
      "Team Health (Retention, Burnout Prevention)",
      "Performance (Capacity Planning)",
      "Stakeholder Mgmt (Priority Negotiation)"
    ],
    "decisionFramework": "1. Candidates in pipeline: Fight for exceptions for the candidate who passed onsite \u2014 they're the hardest to re-recruit later. Present the cost of losing them (recruiting fees, ramp time, offer expiration). For earlier-stage candidates: communicate honestly and keep them warm if possible. 2. Scope reduction: Immediately re-prioritize. With 9 people instead of planned 12, you cannot run 3 full projects. Present leadership with options: (A) 2 projects at full speed + 1 paused, (B) 3 projects at reduced scope, (C) rank order and leadership decides. 3. Retention: Individual conversations with each team member within 1 week. Understand their concerns. Invest in what you CAN offer \u2014 stretch assignments, learning opportunities, conference talks, visibility projects, flexible work arrangements. 4. Burnout mitigation: Reduce meeting load, protect focus time, be explicit about what's NOT getting done. No hero culture. 5. Internal mobility: Can you borrow people from teams with lower priority work? Propose temporary reallocation. 6. Plan for freeze end: Keep job descriptions updated, maintain recruiter relationships, have a priority order for reqs when hiring resumes.",
    "commonMistakes": "Accepting the freeze without fighting for in-pipeline candidates (especially post-onsite \u2014 you'll never get them back). Not adjusting scope to match reduced team (expecting 9 people to do the work of 12). Ignoring retention risk because 'where would they go in this market?' (good engineers always have options). Canceling all development investment (training, conferences, hackathons) \u2014 this is exactly when you need retention tools most. Burning out your best people by giving them the extra work. Not planning for freeze end \u2014 scrambling when hiring reopens wastes months.",
    "whatGoodLooksLike": "Exception secured for post-onsite candidate (or at least a genuine attempt with VP-level advocacy). Scope explicitly reduced and communicated to stakeholders \u2014 no silent over-commitment. Every team member has had a 1:1 within the first week addressing their concerns and growth path. Burnout signals monitored actively \u2014 workload redistributed, low-priority work paused. Zero regrettable attrition during freeze. When hiring reopens: reqs are ready, pipeline is warm, team hits the ground running. Industry reference: Google maintains hiring committee relationships and pipeline data even during freezes, enabling rapid restart when hiring reopens. Amazon's Bar Raiser network preserves interviewer calibration across hiring cycles.",
    "mappingNotes": "Hiring freeze management and retention during constraints",
    "suggestedMetricIds": [
      "7.3",
      "7.5",
      "5.1",
      "7.9"
    ]
  },
  {
    "id": "P-C3-3",
    "slug": "your-product-is-being-sunset-deprecated",
    "observableIds": [
      "C3-O6",
      "C1-O15",
      "C7-O4"
    ],
    "capabilityIds": [
      "C3",
      "C1",
      "C7"
    ],
    "title": "Your Product Is Being Sunset/Deprecated",
    "context": "Leadership decides to sunset your team's product \u2014 a service with 50K active users. Revenue doesn't justify continued investment. Users need to be migrated to an alternative (internal or third-party). Timeline is 9 months. Your team of 10 engineers built this product over 3 years. They're anxious about their futures \u2014 will they be laid off, reassigned, or forgotten?",
    "topicsActivated": [
      "Technical Strategy (Deprecation Planning, User Migration)",
      "Org Design (Team Dissolution/Reassignment)",
      "Team Health (Morale, Career Anxiety)",
      "Stakeholder Mgmt (Communicating Difficult Decisions)",
      "Change Management (Product Lifecycle End)"
    ],
    "decisionFramework": "1. People first (Day 1-3): Before talking about migration plans, address your team's concerns. Be transparent about what you know and don't know. Commit to advocating for every team member's next role. If you have guarantees about no layoffs, say so. If you don't, be honest about the uncertainty. 2. Migration planning (Week 1-2): Assess user segmentation \u2014 which users migrate to what alternative? Create migration tiers: self-serve users (automated migration tools), mid-tier (guided migration with docs), enterprise/high-touch (white-glove migration support). 3. Communication plan (Week 2): Draft user communication in partnership with PM and marketing. Give users maximum notice. Provide clear timelines, migration guides, and support channels. 4. Technical execution (Month 1-8): Build migration tooling, maintain product stability during wind-down (no new features, but fix critical bugs and security issues), decommission infrastructure in phases. 5. Team placement (Month 1-6): Work with your manager and HR to identify landing spots for every team member. Match skills and interests to open roles. Start conversations early \u2014 don't wait until month 8. 6. Knowledge transfer (Month 6-9): Document institutional knowledge, transfer ownership of any shared components, archive code and documentation. 7. Sunset (Month 9): Final user cutover, infrastructure decommission, retrospective on the product lifecycle.",
    "commonMistakes": "Not addressing team anxiety immediately (people start job searching externally on Day 1 if they feel uncertain). Treating migration as an afterthought (50K users migrating poorly creates customer support nightmares and brand damage). Letting product quality degrade during wind-down (users still depend on it until they're migrated). Not fighting for your team members' placement (they remember who advocated for them). Waiting until month 7 to start placing people (best roles are taken). Pretending the product was a failure (it served users for 3 years \u2014 honor that). Not doing a retrospective (valuable lessons about product-market fit, technical decisions, and lifecycle management).",
    "whatGoodLooksLike": "Every team member knows their next role by month 6 \u2014 zero involuntary departures. User migration is smooth: 90%+ migrated with minimal support tickets. Product quality maintained until final cutover \u2014 no embarrassing outages during sunset. User communication is transparent and empathetic \u2014 NPS impact minimized. Team morale stays functional throughout (it won't be great, but it stays professional). Retrospective captures genuine lessons learned. Team members look back and say 'that was hard, but it was handled well.' Industry reference: Amazon's Working Backwards process (starting with the customer PR/FAQ) provides a framework for communicating product sunset with empathy. Google's deprecation policy mandates minimum notice periods and migration support for internal customers.",
    "mappingNotes": "Product sunset, user migration, and team reassignment",
    "suggestedMetricIds": [
      "8.2",
      "8.4",
      "1.2"
    ]
  },
  {
    "id": "P-C2-1",
    "slug": "quarterly-planning-product-engineering-disagree",
    "observableIds": [
      "C2-O1",
      "C2-O2"
    ],
    "capabilityIds": [
      "C2",
      "C5"
    ],
    "title": "Quarterly Planning When Product and Engineering Disagree on Priorities",
    "context": "It's planning season. Product wants to invest heavily in new features for a key customer segment. Engineering wants to pay down critical tech debt that's causing weekly incidents. Both sides have compelling data. You need to facilitate alignment.",
    "topicsActivated": [
      "Strategic Prioritization (Investment Balance)",
      "Cross-Functional Influence (PM Partnership)",
      "Decision Framing (Trade-off Communication)"
    ],
    "decisionFramework": "1. Quantify both sides: feature revenue impact vs. incident cost (engineer time, customer impact, pager fatigue). 2. Find the false dichotomy: can scope be split? Can debt be paid incrementally alongside features? 3. Use a 70/20/10 or similar framework: 70% features, 20% debt, 10% exploration \u2014 adjust ratios with data. 4. Create a shared artifact (investment portfolio view) both sides can see. 5. Agree on metrics to evaluate next quarter whether the split was right. 6. Escalate only if you've genuinely tried to align and can articulate the trade-off crisply.",
    "commonMistakes": "Picking a side instead of facilitating trade-off analysis. Using vague 'tech debt' framing without specific incidents/costs. Letting loudest voice win. Deferring entirely to product ('they own the roadmap'). Committing to both without acknowledging capacity constraints.",
    "whatGoodLooksLike": "Shared investment portfolio document with clear ratios. Both product and engineering feel heard. Trade-offs are explicit and documented. Success metrics defined for both feature and debt investments. Re-evaluation cadence agreed upon. Industry reference: Amazon's 6-pager narrative format forces explicit trade-off documentation between competing investments. Google's OKR framework requires measurable outcomes for both feature and infrastructure investments, preventing either from being 'just trust us.'",
    "mappingNotes": "Strategic prioritization with cross-functional tension",
    "suggestedMetricIds": [
      "8.4",
      "8.1",
      "8.3",
      "1.2"
    ]
  },
  {
    "id": "P-C2-2",
    "slug": "asked-to-build-conflicting-with-okrs",
    "observableIds": [
      "C2-O2",
      "C2-O3"
    ],
    "capabilityIds": [
      "C2",
      "C10"
    ],
    "title": "Asked to Build Something That Conflicts with Your OKRs",
    "context": "A VP from another org asks your team to take on an urgent project that doesn't align with your quarterly OKRs. Your manager seems supportive of helping. Taking this on means dropping or delaying a committed OKR.",
    "topicsActivated": [
      "Strategic Prioritization (Saying No)",
      "Resource Allocation (Scope Management)",
      "Stakeholder Mgmt (Managing Up and Across)"
    ],
    "decisionFramework": "1. Clarify the ask: scope, timeline, why your team specifically. 2. Map impact: what gets dropped or delayed if you say yes. 3. Present trade-off to your manager explicitly: 'We can do X, but Y slips by Z weeks.' 4. If manager says do both: push back with data on capacity. 5. If you take it on: renegotiate OKRs formally \u2014 don't silently absorb. 6. Document the decision and who made it.",
    "commonMistakes": "Silently absorbing the work and burning out the team. Saying yes without surfacing what gets dropped. Saying no without offering alternatives (different team, reduced scope, later timeline). Not looping in your manager before committing. Treating OKRs as immutable when the business context has changed.",
    "whatGoodLooksLike": "Trade-off conversation with manager within 24 hours. Clear written communication to requesting VP with options. OKRs formally adjusted if work is accepted. Team understands why priorities shifted. No hero-mode \u2014 scope is right-sized to capacity. Industry reference: Amazon's 'disagree and commit' principle combined with Type 1/Type 2 decision classification helps managers navigate conflicting priorities \u2014 reversible commitments can flex, irreversible ones need escalation.",
    "mappingNotes": "Priority conflict with cross-org pressure",
    "suggestedMetricIds": [
      "8.1",
      "8.4",
      "8.3"
    ]
  },
  {
    "id": "P-C4-1",
    "slug": "team-delivery-predictability-collapsed",
    "observableIds": [
      "C4-O1",
      "C4-O2",
      "C4-O8"
    ],
    "capabilityIds": [
      "C4",
      "C9"
    ],
    "title": "Your Team's Delivery Predictability Has Collapsed",
    "context": "Over the past two quarters, your team has missed 70% of committed sprint goals. Stakeholders are losing trust. The team feels demoralized and says estimates are impossible given constant interruptions and changing requirements.",
    "topicsActivated": [
      "Operational Leadership (Delivery Cadence)",
      "Metrics & Measurement (Predictability)",
      "Team Health (Morale)"
    ],
    "decisionFramework": "1. Diagnose: categorize why work was missed \u2014 scope creep, interrupts, underestimation, dependencies, or changing priorities? 2. Measure interrupt load: what percentage of sprint capacity goes to unplanned work? 3. Right-size commitments: commit to less, deliver consistently. 4. Protect the sprint: create an interrupt buffer (e.g., 20% unplanned capacity) or designate an interrupt handler rotation. 5. Shorten planning horizon if needed (2-week sprints \u2192 1-week). 6. Rebuild trust: show 3 consecutive on-target deliveries before expanding scope.",
    "commonMistakes": "Adding more process (longer planning, more estimation ceremonies) without addressing root cause. Blaming the team for bad estimates when the real problem is scope creep. Committing to aggressive goals to 'make up' for missed ones. Not addressing the interrupt source (often another team or on-call). Tracking velocity as a performance metric instead of a planning tool.",
    "whatGoodLooksLike": "Root cause analysis completed within 1 week. Interrupt load measured and buffer created. Commitments reduced to 70% of historical capacity. 3 consecutive sprints hitting >80% of commitments. Stakeholders see improving trend and regain trust. Team morale improves as they start hitting goals. Industry reference: Spotify's squad Health Check model provides a structured diagnostic for delivery predictability issues. Google's DORA research identifies four key metrics that, when tracked together, prevent optimizing one dimension at the expense of others.",
    "mappingNotes": "Delivery predictability recovery",
    "suggestedMetricIds": [
      "2.5",
      "1.2",
      "2.6",
      "1.4",
      "5.1"
    ]
  },
  {
    "id": "P-C4-2",
    "slug": "inherit-team-no-operating-cadence",
    "observableIds": [
      "C4-O1",
      "C4-O3",
      "C4-O9"
    ],
    "capabilityIds": [
      "C4"
    ],
    "title": "You Inherit a Team with No Operating Cadence",
    "context": "You've just taken over a team that has no regular standup, no sprint planning, no retrospectives, and no documented on-call process. Work gets done through Slack threads and ad-hoc requests. The team is productive but chaotic, and knowledge is siloed.",
    "topicsActivated": [
      "Operational Leadership (Cadence Design)",
      "Developer Experience (Process)",
      "Culture (Norms)"
    ],
    "decisionFramework": "1. Observe first: spend 2 weeks understanding how work actually flows before changing anything. 2. Identify the biggest pain point (not your biggest concern \u2014 theirs). 3. Introduce ONE ceremony at a time. Start with a weekly sync \u2014 lowest friction, highest visibility. 4. Add planning/retro after the team sees value in the sync. 5. Document decisions and on-call in a shared runbook. 6. Don't over-process: match cadence to team size and maturity. A 4-person team doesn't need SAFe.",
    "commonMistakes": "Introducing 5 new meetings in week 1. Copying your previous team's exact process. Not asking the team what's actually painful. Making process compliance the goal instead of outcomes. Assuming chaos means dysfunction \u2014 sometimes small teams work fine with minimal process.",
    "whatGoodLooksLike": "2-week observation period before changes. Team co-designs the operating cadence. One ceremony introduced per 2-week cycle. Written runbook for on-call within 30 days. Team reports less chaos and fewer knowledge silos within 60 days. Process is lightweight and valued, not resented. Industry reference: Spotify introduces operating cadences incrementally \u2014 starting with a Health Check before adding ceremonies. Amazon's operational excellence model focuses on mechanisms (repeatable processes) rather than good intentions.",
    "mappingNotes": "Operating cadence bootstrapping",
    "suggestedMetricIds": [
      "1.2",
      "1.4",
      "2.5",
      "5.1"
    ]
  },
  {
    "id": "P-C12-3",
    "slug": "your-team-culture-is-deteriorating-after-rapid-growth",
    "observableIds": [
      "C12-O1",
      "C12-O2",
      "C12-O6"
    ],
    "capabilityIds": [
      "C12"
    ],
    "title": "Your Team Culture Is Deteriorating After Rapid Growth",
    "context": "Your team doubled from 6 to 12 in 3 months. Skip-level feedback reveals new hires feel excluded, original team members feel their culture is gone, and collaboration norms are breaking down.",
    "topicsActivated": [
      "Team Health (Culture Continuity)",
      "Onboarding (Cultural Integration)",
      "Communication (Scaling Norms)"
    ],
    "decisionFramework": "1. Diagnose: run anonymous team health survey to quantify the problem. 2. Acknowledge: in team meeting, name the challenge \u2014 growth is hard, culture erosion is natural, and you're going to address it intentionally. 3. Rebuild: facilitate team charter session with ALL members (not just originals) to co-create norms. 4. Pair: create culture buddy system pairing new hires with veterans. 5. Formalize: document onboarding culture guide. 6. Monitor: monthly culture pulse checks for 2 quarters. 7. Adjust: iterate on norms based on feedback.",
    "commonMistakes": "Assuming culture will 'rub off' naturally. Only listening to original team members. Treating it as a one-time off-site exercise. Not documenting norms (they live in people's heads). Blaming new hires for 'not getting it'. Trying to preserve old culture exactly instead of evolving it.",
    "whatGoodLooksLike": "Co-created team charter within 4 weeks of recognizing the problem. New and tenured members both feel ownership of team norms. Culture buddy program running. Monthly pulse checks showing improvement within 2 months. New hires report feeling integrated within 60 days. Industry reference: Spotify uses squad Health Checks to make cultural dimensions explicit and discussable, enabling rapid intervention when scores decline.",
    "mappingNotes": "Culture deterioration during growth scenario",
    "suggestedMetricIds": [
      "7.1",
      "7.2",
      "5.1"
    ]
  },
  {
    "id": "P-C12-4",
    "slug": "addressing-a-toxic-team-member-senior-engineer-others-avoid",
    "observableIds": [
      "C12-O1",
      "C12-O8"
    ],
    "capabilityIds": [
      "C12",
      "C6"
    ],
    "title": "Addressing a Toxic Senior Engineer the Team Works Around",
    "context": "Your most technically skilled senior engineer is dismissive in code reviews, dominates discussions, and makes junior engineers afraid to speak up. The team has learned to 'work around' this person, but you're losing good people.",
    "topicsActivated": [
      "Team Health (Psychological Safety)",
      "Performance (Behavioral Standards)",
      "Culture (Norm Enforcement)"
    ],
    "decisionFramework": "1. Document: collect specific behavioral examples with dates and impact (code review comments, meeting behaviors, peer feedback). 2. Private 1:1: deliver feedback using SBI framework \u2014 specific behavior, its impact on team and business, expected change. 3. Set timeline: clear behavioral expectations with 30-day checkpoint. 4. Support: provide coaching or resources (communication training, mentoring). 5. Monitor: check with team members (without naming) about improvement. 6. Follow through: if no improvement at 30 days, escalate to formal performance process. 7. Communicate: when behavior improves, acknowledge it; if person exits, address team about culture standards.",
    "commonMistakes": "Avoiding the conversation because of the person's technical value. Giving vague feedback like 'be nicer'. Addressing it publicly instead of privately first. Not documenting specific examples. Treating it as a personality issue rather than behavioral impact. Waiting for an HR complaint instead of acting proactively.",
    "whatGoodLooksLike": "Feedback delivered within 1 week of recognizing the pattern. Specific behavioral examples cited. Clear improvement plan with timeline. Psychological safety survey administered before and 30 days after intervention. Outcome: either behavioral improvement or managed exit. Team knows culture standards are enforced regardless of seniority. Industry reference: Netflix's culture memo explicitly states that brilliant jerks are a net negative \u2014 technical skill doesn't exempt anyone from behavioral standards.",
    "mappingNotes": "Toxic senior engineer scenario",
    "suggestedMetricIds": [
      "7.1",
      "5.1",
      "7.2"
    ]
  },
  {
    "id": "P-C10-4",
    "slug": "asked-to-do-more-with-fewer-people-after-layoffs",
    "observableIds": [
      "C10-O2",
      "C10-O6",
      "C10-O8"
    ],
    "capabilityIds": [
      "C10"
    ],
    "title": "Asked to Do More With Fewer People After Layoffs",
    "context": "After a round of layoffs, your team lost 3 of 10 engineers. Leadership still expects the same deliverables. Team morale is low, survivors are anxious, and you need to figure out what's actually possible.",
    "topicsActivated": [
      "Resource Allocation (Capacity Planning)",
      "Stakeholder Mgmt (Expectation Setting)",
      "Team Health (Post-Layoff Recovery)"
    ],
    "decisionFramework": "1. Immediate (Week 1): Acknowledge the loss with the team \u2014 don't pretend things are normal. Address survivor anxiety directly. 2. Assess (Week 1-2): Map remaining capacity honestly. Identify critical path work vs. nice-to-haves. 3. Present options (Week 2-3): Go to leadership with tiered plan \u2014 (A) what's possible with current team, (B) what requires deprioritizing, (C) what needs to stop entirely. Use data, not emotions. 4. Communicate (Week 3): Share the new reality with team and stakeholders. Be specific about what stops. 5. Protect (Ongoing): Shield team from creeping scope. Monitor burnout signals aggressively. 6. Optimize (Month 2+): Identify automation and process improvements that multiply remaining capacity.",
    "commonMistakes": "Accepting all original commitments and expecting the team to absorb the load. Not acknowledging the emotional impact of layoffs. Presenting a single option instead of tiered trade-offs. Burning out remaining team trying to prove the layoffs weren't needed. Not renegotiating timelines with stakeholders. Being vague about what stops \u2014 'we'll try our best' is not a plan.",
    "whatGoodLooksLike": "Honest capacity assessment within 2 weeks. Tiered options presented to leadership with quantified trade-offs. At least 30% of previous scope explicitly deprioritized or stopped. Team morale stabilized within 6 weeks (measured). No additional regrettable departures in the quarter following layoffs. Industry reference: Shopify's 2023 post-layoff playbook focused on radical scope reduction rather than expecting remaining team to absorb the load \u2014 leadership explicitly killed projects proportional to headcount reduction.",
    "mappingNotes": "Post-layoff resource management scenario",
    "suggestedMetricIds": [
      "7.1",
      "5.1",
      "1.2"
    ]
  },
  {
    "id": "P-C7-2",
    "slug": "communicating-a-major-technical-decision-that-not-everyone-agrees-with",
    "observableIds": [
      "C7-O1",
      "C7-O6",
      "C7-O10"
    ],
    "capabilityIds": [
      "C7"
    ],
    "title": "Communicating a Major Technical Decision Not Everyone Agrees With",
    "context": "After an RFC process, you've decided to migrate from microservices back to a modular monolith. Senior engineers are split \u2014 some are excited, others feel their microservices expertise is being devalued. You need to communicate the decision without creating factions.",
    "topicsActivated": [
      "Decision Framing (Controversial Decisions)",
      "Communication (Technical Audience)",
      "Culture (Constructive Disagreement)"
    ],
    "decisionFramework": "1. Document the decision fully: what was decided, why, what alternatives were considered and why they were rejected. 2. Acknowledge dissent: name the strongest counter-arguments and explain specifically why you decided differently. 3. Communicate in writing first: publish the decision doc before the meeting so people can process it. 4. Hold a Q&A: let people ask questions and express concerns without relitigating. 5. Commit explicitly: 'This is the decision. If you disagree, I respect that, and I need you to commit to execution.' 6. Follow up individually: talk to the loudest dissenters 1:1 to address concerns and check for commitment.",
    "commonMistakes": "Announcing without explaining the reasoning. Dismissing disagreement as 'not understanding'. Not documenting the alternative options considered. Relitigating the decision in every meeting. Making it personal \u2014 'I decided' vs. 'we evaluated'. Not following up with dissenters who might sabotage silently.",
    "whatGoodLooksLike": "Decision doc published with alternatives analysis. Team can articulate the reasoning even if they disagreed. Execution begins within 2 weeks. No underground resistance. Dissenters feel heard even though they didn't 'win'. Team retrospective at 90 days evaluates whether the decision is working. Industry reference: Amazon's 'disagree and commit' principle provides a clear framework \u2014 voice disagreement during the decision process, commit fully once the decision is made.",
    "mappingNotes": "Controversial technical decision communication scenario",
    "suggestedMetricIds": [
      "1.2",
      "8.4"
    ]
  },
  {
    "id": "P-C7-3",
    "slug": "your-team-has-communication-debt-decisions-not-documented",
    "observableIds": [
      "C7-O6",
      "C7-O9"
    ],
    "capabilityIds": [
      "C7",
      "C4"
    ],
    "title": "Your Team Has Communication Debt \u2014 Decisions Aren't Documented",
    "context": "Your team has grown from 5 to 15 people. Key technical decisions live in Slack threads, hallway conversations, and individual memories. New hires can't find context. The same decisions are relitigated monthly. You're drowning in 'quick syncs'.",
    "topicsActivated": [
      "Communication (Documentation Practices)",
      "Decision Making (Process Design)",
      "Operational Rhythm (Scaling)"
    ],
    "decisionFramework": "1. Audit: List the top 10 decisions made in the last quarter \u2014 can you find the documentation? If not, you have communication debt. 2. Triage: retroactively document the most impactful undocumented decisions (tech choices, process decisions, ownership assignments). 3. Introduce lightweight RFC process: not bureaucratic \u2014 a simple template for decisions that affect >2 people. 4. Create decision log: a single page listing recent decisions with links to context. 5. Establish norms: 'If it was decided in Slack, it didn't happen until it's in the decision log.' 6. Review: monthly audit of decision documentation completeness.",
    "commonMistakes": "Making the RFC process too heavy (kills adoption). Not retroactively documenting the most critical past decisions. Expecting the team to change overnight (habits take weeks). Documenting everything (leads to documentation fatigue). Not having a single searchable location for decisions. Confusing meeting notes with decision documentation.",
    "whatGoodLooksLike": "Within 6 weeks: lightweight RFC template adopted, decision log created and maintained, new hires can find context for major decisions without asking. Within 3 months: same-decision relitigations drop measurably. Communication overhead per person decreases as team scales. Industry reference: Spotify's decision log (DACI-based) ensures every significant decision has a single documented source of truth accessible to the entire squad and stakeholders.",
    "mappingNotes": "Communication debt and documentation scaling scenario",
    "suggestedMetricIds": [
      "1.2",
      "2.1"
    ]
  },
  {
    "id": "P-C14-3",
    "slug": "high-performer-wants-promotion-but-isnt-ready",
    "observableIds": [
      "C14-O5",
      "C14-O8"
    ],
    "capabilityIds": [
      "C14",
      "C6"
    ],
    "title": "High Performer Wants Promotion But Isn't Ready",
    "context": "Your best engineer is pushing hard for promotion to Senior. They're technically excellent and deliver consistently, but they lack the influence, mentoring, and scope leadership expected at the next level. They're getting impatient and you're worried about retention.",
    "topicsActivated": [
      "Performance (Promotion Readiness)",
      "Coaching (Development Planning)",
      "Retention (Managing Expectations)"
    ],
    "decisionFramework": "1. Validate: Review the level expectations document and honestly assess where the engineer is vs. where they need to be. 2. Prepare the conversation: document specific gaps with examples (not 'you need more leadership' but 'at Senior level, you'd need to have led a cross-team initiative end-to-end'). 3. Deliver with care: acknowledge their strengths, name the specific gaps, and frame it as 'here's what we're building toward' not 'you're not good enough'. 4. Co-create a plan: identify 2-3 specific stretch opportunities over the next 6 months that address the gaps. 5. Commit to support: regular check-ins on progress, sponsor for the right opportunities, provide visibility. 6. Manage retention: separate promo from retention \u2014 explore comp adjustment, scope expansion, or recognition to address flight risk without premature promotion.",
    "commonMistakes": "Promoting to retain (creates level inflation and sets them up to fail). Vague feedback like 'you need more scope'. Not separating retention from promotion \u2014 they're different problems. Saying 'maybe next cycle' without a concrete plan. Comparing them to others who were promoted. Not sponsoring opportunities that would fill the gaps. Over-promising timeline for promotion.",
    "whatGoodLooksLike": "Specific gap analysis delivered within 2 weeks. 6-month development plan with concrete milestones co-created. At least one stretch assignment initiated within 30 days. Monthly check-ins on progress. Engineer feels invested in (not rejected). If comp is the real issue, address it separately. Industry reference: Google's promo committee model requires sustained next-level evidence across multiple review periods \u2014 managers coach to the bar rather than lowering it, and use 'development partnership' framing to retain ambitious engineers.",
    "mappingNotes": "Promotion readiness gap management scenario",
    "suggestedMetricIds": [
      "5.1",
      "7.1"
    ]
  }
]