[
  {
    "anchorId": "C1-1",
    "capabilityId": "C1",
    "sourceTopic": "Org Design & Team Topologies",
    "level1Developing": "Inherits team structure and works within it. Recognizes ownership confusion when it causes problems. Understands Conway's Law conceptually but doesn't apply it proactively.",
    "level2Emerging": "Recognizes when team structure causes friction. Beginning to track ownership gaps. Starts to think about Conway's Law in practice but doesn't initiate structural changes.",
    "level3Competent": "Assesses team cognitive load and advocates for structural changes. Maintains clear ownership registry. Proposes and executes team splits/merges when needed. Applies Conway's Law to align architecture and org structure.",
    "level4Distinguished": "Proactively proposes team topology changes based on cognitive load analysis and value-stream mapping, influencing org-level design before bottlenecks surface. Executes team changes with minimal disruption. Conway's Law applied intentionally to shape architecture through team structure.",
    "level5Advanced": "Designs team topology for the org. Re-orgs executed with <1 regrettable departure per re-org cycle. Platform team justification and creation. Inverse Conway maneuver applied successfully. Team topology rationale articulated to VP+ with architectural alignment evidence. Company benchmark: Amazon's org design principles — single-threaded ownership, two-pizza teams, and API boundaries between teams — exemplify this level of structural thinking applied at scale.",
    "rationale": "Anchor 1/2: Covers structural design (team splits/merges, ownership, Conway's Law). Maps to C1-O1 through C1-O5."
  },
  {
    "anchorId": "C1-2",
    "capabilityId": "C1",
    "sourceTopic": "Cross-Team Strategy & Long-Horizon Planning",
    "level1Developing": "Focuses on own team's goals without considering cross-team impact. Planning horizon limited to current quarter. Relies on manager for org-level context and strategic direction.",
    "level2Emerging": "Beginning to track dependencies across adjacent teams. Starting to consider 2-quarter planning horizons. Occasionally contributes to org-level discussions when invited.",
    "level3Competent": "Proactively manages cross-team dependencies and alignment. 3-4 quarter planning horizon with clear milestones. Translates business strategy into team-level goals with explicit success criteria. Contributes to org-level strategy discussions. Identifies systemic issues that cross team boundaries.",
    "level4Distinguished": "Drives cross-team initiatives spanning multiple quarters. Anticipates org-level shifts and positions team accordingly. Influences strategic direction beyond own scope. Beginning to represent org perspective to senior leadership.",
    "level5Advanced": "Sets multi-year strategic direction for the org. Drives cross-org alignment on complex, ambiguous initiatives. Translates company strategy into team goals with measurable outcomes and cross-team dependency maps. Strategic thinking sought by VP+ leadership. Legacy decisions create lasting positive impact across the organization. Company benchmark: Google's cross-org alignment processes and Amazon's multi-year strategic planning (Working Backwards PR/FAQ) demonstrate how elite orgs sustain long-horizon thinking across teams.",
    "rationale": "Anchor 2/2: Covers strategic leadership altitude (multi-quarter planning, cross-team alignment, org-level influence, strategy-to-team translation). Maps to C1-O6 through C1-O16. Intentionally separate from structural design — strategy vs. structure are distinct sub-skills."
  },
  {
    "anchorId": "C2-1",
    "capabilityId": "C2",
    "sourceTopic": "Strategic Alignment & Roadmapping",
    "level1Developing": "Plans reactively (PM tells you what to build). OKRs exist but are task lists. Engineering impact described in technical terms. Trade-offs implicit, not communicated.",
    "level2Emerging": "Beginning to participate in planning beyond task execution. Starting to write OKRs with some outcome focus. Trade-offs acknowledged but not consistently documented.",
    "level3Competent": "Structured quarterly planning with capacity model. Outcome-oriented OKRs (max 3 per team). Engineering impact translated to business metrics. Trade-offs explicit in planning docs with 'what we're NOT doing' section. Roadmap communicated at multiple altitudes.",
    "level4Distinguished": "Planning process adopted by adjacent teams. OKRs consistently outcome-oriented with measurable results. Engineering impact articulated in business terms that leadership values. Strategic partnership with PM emerging at org level.",
    "level5Advanced": "Org-level planning drives cross-team alignment. OKRs directly tied to company strategy with measurable outcomes. Engineering ROI articulated in board-level business terms. Planning process is the standard others adopt. Strategic partner to PM/business leadership. Company benchmark: Amazon's PR/FAQ process forces opportunity-cost thinking before any initiative starts, and Google's OKR framework ties every team's goals measurably to company strategy.",
    "rationale": "Anchor 1/2: Covers strategic planning mechanics (planning process, OKRs, roadmapping, capacity models). Maps to C2-O1, C2-O5, C2-O6."
  },
  {
    "anchorId": "C2-2",
    "capabilityId": "C2",
    "sourceTopic": "Trade-Off Discipline & Decision Rigor",
    "level1Developing": "Difficulty saying no to requests. Trade-offs implicit or avoided. Decisions escalated or deferred rather than framed. First principles thinking is aspirational, not practiced.",
    "level2Emerging": "Beginning to push back on requests with basic trade-off framing. Starting to differentiate reversible from irreversible decisions. Maintains informal sense of what's not being done but doesn't communicate it explicitly.",
    "level3Competent": "Declines requests by making trade-offs visible ('yes, if we deprioritize X'). Maintains explicit 'not doing' list communicated to stakeholders. Matches decision rigor to reversibility — ships fast on reversible choices, invests analysis on irreversible ones. Challenges assumptions with first principles when the situation demands it.",
    "level4Distinguished": "Trade-off framing is a recognized strength. 'Not doing' list referenced by stakeholders as a planning tool. Decision rigor calibrated well — avoids both analysis paralysis and reckless speed. First principles thinking produces novel insights that influence team direction.",
    "level5Advanced": "Trade-off discipline is an org model — other teams adopt the practice. Strategic 'not doing' decisions create organizational clarity and focus. Decision framework handles ambiguity at scale. First principles thinking produces novel solutions that influence org strategy. Company benchmark: Amazon's 'disagree and commit' principle and Type 1/Type 2 decision framework provide structural clarity for balancing speed with rigor at scale.",
    "rationale": "Anchor 2/2: Covers prioritization discipline (saying no, trade-off framing, decision rigor, first principles thinking). Maps to C2-O2, C2-O3, C2-O4. Intentionally separate from planning mechanics — strategic discipline vs. process execution are distinct sub-skills."
  },
  {
    "anchorId": "C3-1",
    "capabilityId": "C3",
    "sourceTopic": "Technical Strategy & System Ownership",
    "level1Developing": "Follows existing technical direction set by TL/Staff. Participates in design reviews. Aware of tech debt but doesn't prioritize it systematically. Relies on senior engineers for architecture decisions.",
    "level2Emerging": "Participates in design reviews with growing confidence. Starting to form technical opinions beyond own team's scope. Beginning to advocate for system health improvements based on data.",
    "level3Competent": "Co-authors tech strategy with TL/Staff. Runs design reviews with clear criteria. Understands system health metrics and acts on them. Makes build-vs-buy decisions with TCO analysis.",
    "level4Distinguished": "Technical strategy extends beyond own team. Design review process refined and adopted by peers. Architecture decisions influenced by system-wide thinking. Starting to drive platform-level technical direction.",
    "level5Advanced": "Sets multi-quarter technical vision that senior engineers follow. Architecture review process institutionalized across teams. Drives platform thinking across org. Recognized as technical strategy leader by peers. Company benchmark: Google's design doc culture and architecture review process scale technical governance across thousands of engineers without creating bottlenecks.",
    "rationale": "Anchor 1/2: Covers technical vision, design reviews, and system ownership. Maps to C3-O1, C3-O2, C3-O5 through C3-O8."
  },
  {
    "anchorId": "C3-2",
    "capabilityId": "C3",
    "sourceTopic": "Tech Debt & Platform Investment",
    "level1Developing": "Acknowledges tech debt exists but doesn't track or prioritize it systematically. Build-vs-buy decisions are ad hoc. No framework for evaluating platform opportunities.",
    "level2Emerging": "Tracks tech debt informally. Makes occasional build-vs-buy arguments with basic cost comparison. Starting to allocate sprint time for debt reduction but without consistent tracking.",
    "level3Competent": "Manages tech debt allocation (15-20% of sprint capacity per quarter, excluding emergency hotfixes). Quantifies tech debt in business terms with cost-of-delay and remediation estimates. Makes build-vs-buy decisions with TCO analysis. Identifies platform opportunities for team-level reuse. Tracks tech debt impact on velocity.",
    "level4Distinguished": "Proactively identifies systemic tech debt across team boundaries. Tech debt proposals include measured velocity impact. Influences org-wide standards. Evaluates platform investment ROI across multiple teams.",
    "level5Advanced": "Strategic tech debt paydown with measurable velocity impact across the org. Tech debt quantified in business terms and presented to leadership with ROI justification. Drives platform thinking that creates org-wide leverage. Platform investments justified with multi-team ROI. Recognized as technical strategy leader for investment prioritization. Company benchmark: Amazon treats tech debt and platform investment as first-class budget line items with measurable ROI, reviewed in weekly business reviews alongside feature delivery.",
    "rationale": "Anchor 2/2: Covers tech debt management, build-vs-buy, and platform investment decisions. Maps to C3-O3, C3-O4, C3-O9 through C3-O11. Intentionally separate from technical vision — investment prioritization is a distinct sub-skill."
  },
  {
    "anchorId": "C4-1",
    "capabilityId": "C4",
    "sourceTopic": "Operating Cadence & Process",
    "level1Developing": "Follows existing processes. Sprint velocity inconsistent. Interrupts handled reactively. Remote practices undefined.",
    "level2Emerging": "Beginning to establish regular operating cadence. Some improvement in sprint predictability. Interrupt management emerging but inconsistent. Remote practices being documented.",
    "level3Competent": "Clear operating cadence with defined outputs. Interrupt rotation implemented. Remote-first practices documented. Retrospective action items tracked to completion. Velocity bottlenecks diagnosed with value stream analysis. Engineers have 4+ hours of daily focus time protected by structural calendar policies.",
    "level4Distinguished": "Operating cadence is efficient and self-reinforcing. Teams largely self-manage within established processes. Toil reduction is systematic. Remote/hybrid practices producing measurable engagement results.",
    "level5Advanced": "Operating rhythm is the org standard. Teams self-manage within cadence. Toil systematically eliminated. Systemic velocity analysis and focus time protection are organizational norms. Remote/hybrid practices produce equal engagement across locations. Company benchmark: Spotify's squad Health Check model provides leading indicators of operational health, and Amazon's operational excellence reviews institutionalize mechanisms over good intentions.",
    "rationale": "Anchor 1/2: Covers team operating system (cadence, process, interrupts, remote practices, velocity diagnosis, focus time protection). Maps to C4-O1, C4-O7 through C4-O13."
  },
  {
    "anchorId": "C4-2",
    "capabilityId": "C4",
    "sourceTopic": "Delivery Predictability & Execution",
    "level1Developing": "Sprint velocity inconsistent. Scope creep is common. Commitments are aspirational rather than evidence-based. Delivery risks surface late in the cycle.",
    "level2Emerging": "Beginning to track delivery metrics. Some improvement in scope management. Risks identified mid-sprint but mitigation is reactive. Starting to use data for capacity planning.",
    "level3Competent": "Meeting 85%+ of committed scope for 3+ consecutive quarters. Capacity model accounts for interrupts, on-call, and PTO. Risks flagged early with mitigation plans. Scope negotiated proactively with stakeholders.",
    "level4Distinguished": "Delivery predictability consistently high even under pressure. Capacity model refined continuously based on actuals. Teams self-manage scope trade-offs within clear boundaries. Beginning to standardize delivery practices across adjacent teams.",
    "level5Advanced": "Delivery practices are the org standard. Teams self-manage within cadence with minimal oversight. Predictability maintained through organizational change. Cross-team delivery coordination is seamless. Company benchmark: Google's DORA research demonstrates that elite delivery teams maintain high predictability alongside high velocity — the two are complementary, not competing.",
    "rationale": "Anchor 2/2: Covers delivery outcomes (predictability, capacity planning, scope management). Maps to C4-O2 through C4-O6. Intentionally separate from cadence — process vs. outcomes are distinct sub-skills."
  },
  {
    "anchorId": "C5-1",
    "capabilityId": "C5",
    "sourceTopic": "Cross-Functional Partnership",
    "level1Developing": "Works with PM on features but relationship is transactional. Design involvement is late. Dependencies are managed reactively. TPM relationship undefined.",
    "level2Emerging": "Building working relationship with PM beyond feature handoffs. Design involvement improving but still sometimes late. Starting to manage dependencies more proactively.",
    "level3Competent": "Healthy triad with PM/Design (regular syncs, shared ownership, constructive disagreements). Shared success metrics across Eng/PM/Design with regular triad syncs. Technical input shapes product direction. Dependencies negotiated proactively. TPM partnership has clear division of labor. DS and platform partnerships structured.",
    "level4Distinguished": "Triad relationship is strong and productive. Technical insights regularly shape product direction. Cross-functional partnerships produce results recognized by leadership. Partner feedback consistently positive.",
    "level5Advanced": "Triad is a model for the org. Shared OKRs and joint retrospectives are standard practice. Product strategy influenced by technical insights. Cross-org partnerships brokered at scale. Legal/privacy partnerships proactive. Partner feedback is consistently strong across all functions. Company benchmark: Meta's cross-functional triad model with shared OKRs and joint retrospectives treats Eng/PM/Design as co-equal owners of outcomes, not separate reporting chains.",
    "rationale": "Anchor 1/2: Covers peer-level cross-functional relationships (PM/Design triad, TPM, DS, platform partnerships, triad alignment cadence). Maps to C5-O1 through C5-O5, C5-O16."
  },
  {
    "anchorId": "C5-2",
    "capabilityId": "C5",
    "sourceTopic": "Upward Management & Sponsor Building",
    "level1Developing": "Relationship with manager is status-update focused. No sponsor relationships. Scope expansion happens to them, not by them. Political dynamics invisible or confusing.",
    "level2Emerging": "Beginning to invest in manager relationship beyond status updates. Recognizes the importance of sponsors and political capital. Starting to navigate org dynamics with awareness.",
    "level3Competent": "Manager relationship is strategic — proactive alignment, early risk signaling, mutual trust. Building sponsor relationships through consistent delivery and visibility. Navigates political dynamics constructively. Beginning to expand scope through demonstrated capability.",
    "level4Distinguished": "Manager actively sponsors growth opportunities. Multiple sponsors across leadership. Political capital used constructively to drive cross-team outcomes. Scope expansion proposals consistently win support.",
    "level5Advanced": "Sponsors at VP+ level actively advocate. Trusted advisor to senior leaders across the org. Political capital compounds through reputation. Scope expanded based on demonstrated strategic judgment. Others seek them for advice on navigating organizational dynamics. Company benchmark: Amazon's Leadership Principles expect leaders to actively build sponsor relationships and 'Earn Trust' through consistent delivery and transparent communication with senior leadership.",
    "rationale": "Anchor 2/2: Covers upward influence (managing up, sponsor relationships, political capital, scope navigation). Maps to C5-O6 through C5-O15. Intentionally separate from peer partnerships — upward influence is a distinct sub-skill."
  },
  {
    "anchorId": "C6-1",
    "capabilityId": "C6",
    "sourceTopic": "Team Health & Execution",
    "level1Developing": "Holds 1:1s but they're mostly status updates. Avoids difficult conversations. Capacity planning is rough estimate. Handles retention reactively (after notice given). Struggles with adversity communication.",
    "level2Emerging": "1:1s improving — mixing status with some career discussion. Beginning to address performance issues (though slowly). Capacity model emerging. Retention mostly reactive but starting to notice flight risk signals.",
    "level3Competent": "1:1s are trust-building with career development mix. Addresses underperformance within 2 weeks of identification. Capacity model accounts for interrupts, on-call, PTO. Retention managed proactively (stay interviews, flight risk identification). Leads team through adversity with honest communication.",
    "level4Distinguished": "Team scores 4.0+ on psychological safety survey (Edmondson scale or equivalent) and trending upward. Performance issues addressed promptly and constructively. Capacity model refined and accurate. Proactive retention achieving results — team members cite manager as reason for staying.",
    "level5Advanced": "Team scores 4.0+ on psychological safety survey (Edmondson scale or equivalent) consistently. Zero avoidance of difficult conversations. Team executes predictably at sustainable pace. <1 regrettable departure per 12 engineers per rolling 12 months. Team navigates crises with minimal productivity loss. Company benchmark: Google's Project Oxygen and manager effectiveness research identified coaching as the #1 behavior distinguishing great managers, measured through anonymous upward feedback surveys.",
    "rationale": "Anchor 1/2: Covers EM-level coaching (1:1s, underperformance, retention, stretch assignments, Staff+ management, career development). Maps to C6-O1 through C6-O5, C6-O8 (stay interviews), C6-O9 (Staff+ management), C6-O10 (career conversations), C6-O13 (career pathways)."
  },
  {
    "anchorId": "C6-2",
    "capabilityId": "C6",
    "sourceTopic": "Managing Managers (Director Track)",
    "level1Developing": "n/a at EM level. Early Director: still doing EM-level work. Skip-levels infrequent or awkward. EMs operate independently without cross-calibration. Delegation is uncomfortable.",
    "level2Emerging": "n/a at EM level. Early Director: beginning to establish skip-level rhythm. Starting to coach EMs beyond project management. Cross-calibration conversations starting. Delegation improving.",
    "level3Competent": "Regular skip-level 1:1s providing org insight. EMs coached on management craft (not just project management). Cross-EM calibration sessions before perf cycles. Delegation boundaries clear. EM bench strength being developed.",
    "level4Distinguished": "Skip-levels providing actionable org insights. EMs coached on full management craft. Cross-EM calibration well-established. Delegation boundaries clear and respected. EM bench showing readiness for growth.",
    "level5Advanced": "EMs are independently strong leaders. Skip-level insights drive proactive org interventions. Calibration standards consistent across all EMs. EM pipeline producing ready managers. Director operates at Director altitude consistently. Org health monitored and maintained systematically. Company benchmark: Amazon evaluates Directors on how independently their EMs operate — Director-level heroics are a failure mode, not a strength.",
    "rationale": "Anchor 2/2: Covers Director-level EM development (coaching EMs, skip-levels, bench building, succession planning). Maps to C6-O6, C6-O7, C6-O11 (coaching struggling EMs), C6-O12 (succession plans). Intentionally separate — different altitude of practice."
  },
  {
    "anchorId": "C7-1",
    "capabilityId": "C7",
    "sourceTopic": "Stakeholder Management & Influence",
    "level1Developing": "Communicates status when asked. Frames asks in engineering terms. Delivers bad news late or sugar-coated. Political capital not actively built. No executive presence.",
    "level2Emerging": "Starting to provide proactive updates without being asked. Beginning to frame proposals with some business context. Bad news delivery improving but still sometimes delayed.",
    "level3Competent": "Proactive weekly written updates. Proposals framed in business terms with ROI. Bad news delivered early with mitigation plan. Political capital built through consistent delivery and helping others. Demonstrates comfort in exec reviews.",
    "level4Distinguished": "Communication trusted by leadership. Proposals consistently well-framed with business impact. Bad news delivered early with clear mitigation options. Political capital built through consistent follow-through. Demonstrates comfort and effectiveness in exec reviews.",
    "level5Advanced": "Leadership trusts completely — maximum autonomy earned. Cross-org alignment driven without escalation. Executive communication is crisp and confident. Sponsors at VP+ level actively advocate for you. Seen as a leader beyond engineering function. Company benchmark: Amazon's 6-pager narrative format eliminates slide-deck hand-waving and forces structured thinking, while Netflix's 'context, not control' model delegates decisions with clear strategic framing.",
    "rationale": "Anchor 1/2: Covers external-facing communication (status updates, bad news delivery, exec presentations, managing up, difficult conversations, communication scaling). Maps to C7-O2 through C7-O5, C7-O8 (difficult conversations), C7-O9 (communication scaling), C7-O11 (explicit trade-off communication)."
  },
  {
    "anchorId": "C7-2",
    "capabilityId": "C7",
    "sourceTopic": "Decision Making & Prioritization",
    "level1Developing": "Decisions made in meetings without documentation. Difficulty saying no. Most decisions escalated or deferred. First principles thinking is aspirational, not practiced.",
    "level2Emerging": "Some decisions documented but inconsistently. Starting to differentiate reversible from irreversible decisions. Beginning to push back on requests with basic trade-off framing.",
    "level3Competent": "DACI/RFC culture established. Decisions classified by reversibility and handled appropriately. Says no with trade-off framing. First principles analysis applied to significant decisions. Systems thinking catches second-order effects.",
    "level4Distinguished": "Decision framework adopted within team and recognized by peers. Prioritization under ambiguity is a developing strength. First principles thinking applied regularly. Systems thinking catches most second-order effects.",
    "level5Advanced": "Decision framework is the org standard. Prioritization under ambiguity is a strength — forward progress in uncertain situations. First principles thinking produces novel solutions. Systems thinking prevents cross-org negative externalities. Decision quality recognized by peers and leadership. Company benchmark: Amazon's Type 1/Type 2 decision framework and 'disagree and commit' principle provide structural clarity for decision-making at scale.",
    "rationale": "Anchor 2/2: Covers decision architecture (DACI/RFC, trade-off framing, reversibility, authority distribution). Maps to C7-O1, C7-O6, C7-O7, C7-O10 (decision authority distribution). Intentionally separate — communication vs decision-making are distinct sub-skills."
  },
  {
    "anchorId": "C8-1",
    "capabilityId": "C8",
    "sourceTopic": "Incident Response & Command",
    "level1Developing": "Participates in incident response. Post-mortems happen but action items slip. On-call exists but rotation health isn't tracked. Launches happen without formal readiness review.",
    "level2Emerging": "More active in incident response. Post-mortems happening consistently but action item follow-through improving. On-call rotation exists and basic health metrics being tracked.",
    "level3Competent": "Incident command process defined and practiced. Post-mortem action item completion >90%. On-call health tracked (page volume, false positives, off-hours pages). Launch readiness checklist enforced. Game days run quarterly.",
    "level4Distinguished": "Incident response is a team strength. Post-mortem culture is exemplary — blameless and actionable. On-call health continuously improving. Cross-team incident learning starting. Game days revealing and addressing novel failure modes.",
    "level5Advanced": "Org-level incident process owned and continuously improved. Cross-org failure mode analysis. On-call health exemplary (teams want to be on your rotation). Incident patterns analyzed across teams. Culture of proactive resilience building. Company benchmark: Google SRE's error budget model makes reliability investment decisions data-driven — teams spend their error budget on velocity and earn it back through stability.",
    "rationale": "Anchor 1/2: Covers reactive operational excellence (incident command, post-mortems, on-call health). Maps to C8-O1 through C8-O3."
  },
  {
    "anchorId": "C8-2",
    "capabilityId": "C8",
    "sourceTopic": "Systemic Risk Reduction",
    "level1Developing": "Risk management is reactive — responds to incidents after they happen. No proactive failure mode analysis. Launch readiness is informal. Dependency risks unknown.",
    "level2Emerging": "Beginning to think about risk proactively. Starting to conduct failure mode analysis for major launches. Some game day participation. Launch readiness checklist emerging.",
    "level3Competent": "Proactive failure mode analysis for all significant changes. Launch readiness reviews enforced with documented criteria. Dependency risks mapped and mitigated. Vendor risk registry maintained for critical dependencies.",
    "level4Distinguished": "Risk reduction is systematic across team portfolio. Cross-team failure modes identified and addressed. Game days reveal novel failure modes that get fixed. Teams proactively build resilience. Starting to influence org-wide risk practices.",
    "level5Advanced": "Org-level risk reduction framework owned and continuously improved. Cross-org failure mode analysis prevents systemic incidents. Culture of proactive resilience building. Vendor dependency abstraction reduces single-point-of-failure risk across the org. Company benchmark: Netflix's chaos engineering practice (Chaos Monkey) proactively tests resilience, and Amazon's pre-mortem process identifies failure modes before they occur in production.",
    "rationale": "Anchor 2/2: Covers proactive risk management (failure mode analysis, launch readiness, dependency risk, vendor management, chaos engineering, error budgets). Maps to C8-O4 through C8-O6, C8-O7 (chaos engineering and game days), C8-O8 (error budget management). Intentionally separate from incident response — proactive vs. reactive are distinct sub-skills."
  },
  {
    "anchorId": "C9-1",
    "capabilityId": "C9",
    "sourceTopic": "Metric Selection & Dashboard Design",
    "level1Developing": "Aware of DORA metrics but doesn't track consistently. Follows existing release processes. Notices developer experience issues but doesn't systematically address them. Sprint management is reactive.",
    "level2Emerging": "Starting to track DORA metrics. Some awareness of team's developer experience gaps. Sprint health improving but inconsistent. Beginning to identify and address toil.",
    "level3Competent": "Reviews DORA metric dashboard weekly; discusses trends in team standup at least biweekly. Owns release quality and process for team. Runs developer experience improvements quarterly (top 2 pain points). Meeting 85%+ sprint commitment accuracy for 3+ consecutive quarters. Toil tracked and reduced systematically.",
    "level4Distinguished": "DORA metrics trending toward elite levels. Developer experience investments showing measurable ROI. Delivery practices being adopted by adjacent teams. Engineering productivity data used in leadership discussions.",
    "level5Advanced": "DORA metrics at elite level across teams. Developer experience investments justified with ROI data. Delivery practices standardized across org. Teams benchmark against each other constructively. Engineering productivity narrative presented to leadership. Company benchmark: Google and Microsoft's SPACE framework balances satisfaction, performance, activity, communication, and efficiency — preventing any single metric from dominating the productivity narrative.",
    "rationale": "Anchor 1/2: Covers metric infrastructure (DORA tracking, developer experience, delivery metrics, dashboards, metric pairings, maturity adaptation). Maps to C9-O1 through C9-O3, C9-O7, C9-O9 (metric pairings), C9-O10 (metric maturity adaptation)."
  },
  {
    "anchorId": "C9-2",
    "capabilityId": "C9",
    "sourceTopic": "Data-Driven Decision Making",
    "level1Developing": "Decisions based on intuition or anecdotes. Metrics reviewed only when asked. No regular review cadence. Engineering impact described in technical terms, not business outcomes.",
    "level2Emerging": "Starting to reference data in decision-making. Reviews team metrics periodically but doesn't act on trends consistently. Beginning to articulate engineering impact in outcome terms.",
    "level3Competent": "Engineering investments justified with data. OKRs measured with leading and lagging indicators. Impact articulated in quantitative business terms. Experiment results inform product and engineering decisions.",
    "level4Distinguished": "Data fluency influences peers and leadership decisions. Proactively identifies metric gaps. Experiment results drive product and engineering strategy. Beginning to establish measurement standards across adjacent teams.",
    "level5Advanced": "Engineering investment narrative presented to leadership with rigorous data and ROI analysis. Measurement standards adopted across org. A/B testing governance with mandatory power analysis established. ROI framing for engineering investment is a recognized organizational strength. Company benchmark: Amazon's 6-pager culture requires data-backed narratives for every engineering investment, and Stripe's developer productivity research ties engineering metrics to business outcomes.",
    "rationale": "Anchor 2/2: Covers decision-making with data (OKR measurement, business impact articulation, experimentation, ROI framing). Maps to C9-O4 through C9-O6, C9-O8. Intentionally separate from metric infrastructure — collecting data vs. using data are distinct sub-skills."
  },
  {
    "anchorId": "C10-1",
    "capabilityId": "C10",
    "sourceTopic": "Budget, Headcount & Resource Planning",
    "level1Developing": "Requests headcount without financial framing. Cloud costs not tracked at team level. Build-vs-buy decisions are gut feel. Budget is someone else's problem.",
    "level2Emerging": "Beginning to think about headcount in terms of ROI. Starting to track cloud costs at team level. Some awareness of build-vs-buy trade-offs. Budget awareness growing.",
    "level3Competent": "Headcount justified with ROI analysis. Cloud costs attributed and optimized per service. Build-vs-buy uses TCO framework. Contractor strategy is principled. Budget defense prepared for cuts.",
    "level4Distinguished": "Headcount cases consistently win approval. Cloud costs optimized with clear attribution. Build-vs-buy decisions are rigorous and well-documented. Contractor strategy principled. Budget stewardship recognized by finance partners.",
    "level5Advanced": "Org-level headcount narrative wins at VP/finance level. FinOps culture established across teams. Engineering investment framed as business asset with measurable returns. Proactive cost optimization (savings reinvested). Trusted steward of company resources. Company benchmark: Netflix's 'highly aligned, loosely coupled' model lets teams self-allocate within strategic guardrails, and Amazon's FinOps culture treats cost as a first-class engineering constraint.",
    "rationale": "Anchor 1/2: Covers financial stewardship (headcount justification, cloud costs, build-vs-buy, contractor strategy). Maps to C10-O1, C10-O3, C10-O4, C10-O5."
  },
  {
    "anchorId": "C10-2",
    "capabilityId": "C10",
    "sourceTopic": "Strategic Reallocation & ROI Framing",
    "level1Developing": "Resources stay where they were assigned regardless of changing priorities. No framework for comparing ROI across investments. Reacts to cuts rather than proactively optimizing allocation.",
    "level2Emerging": "Beginning to evaluate resource allocation against impact. Some awareness that reallocation is a tool, not just a response to cuts. Starting to frame engineering investments in outcome terms.",
    "level3Competent": "Presents resource requests as tiered options with quantified trade-offs at each level. Tracks cost-per-outcome to demonstrate engineering ROI. Proactively reallocates capacity to highest-impact work without waiting for top-down direction. During cuts, communicates explicitly what stops — not just what continues.",
    "level4Distinguished": "Tiered resource proposals consistently win approval. Cost-per-outcome tracking influences leadership decisions. Proactive reallocation is a team operating norm. Reallocation proposals backed by data and adopted within a week.",
    "level5Advanced": "Resource allocation narrative presented at VP/finance level with rigorous ROI analysis. Proactive cost optimization generates savings that are reinvested in high-impact areas. Engineering investment framing is a recognized organizational capability. Teams across org adopt similar ROI tracking practices. Company benchmark: Amazon's FinOps culture treats cost as a first-class engineering constraint, with weekly business reviews comparing cost-per-outcome across teams and reinvesting savings into highest-ROI initiatives.",
    "rationale": "Anchor 2/2: Covers dynamic allocation (tiered proposals, ROI tracking, proactive reallocation, cut communication). Maps to C10-O2, C10-O6, C10-O7, C10-O8. Intentionally separate from financial stewardship — static budgeting vs. dynamic allocation are distinct sub-skills."
  },
  {
    "anchorId": "C11-1",
    "capabilityId": "C11",
    "sourceTopic": "Hiring Process & Bar Raising",
    "level1Developing": "Participates in hiring loops. Onboarding is informal (buddy system if lucky). Headcount requests are 'we need more people.' No engineering brand presence.",
    "level2Emerging": "Hiring loops becoming more structured. Some onboarding documentation exists. Starting to justify headcount with basic data. Referral network emerging.",
    "level3Competent": "Calibrated hiring loops with trained interviewers and rubrics. Structured interview processes evaluate demonstrated competencies over pedigree. Headcount justified with capacity model and business impact. Referral pipeline active. Bar raiser discipline maintained under hiring pressure. Hiring funnel conversion tracked at each stage.",
    "level4Distinguished": "Hiring bar consistently maintained. Interview calibration program running. Headcount narrative connects to business strategy. Interviewer training producing calibrated assessors. Diverse candidate slates achieved consistently.",
    "level5Advanced": "Bar raiser discipline maintained under pressure. Interviewer calibration is org model. Headcount cases win at VP level. Hiring process produces consistently strong signal with high inter-rater reliability. Competitive hiring strategy wins talent beyond compensation through differentiated value proposition. Hiring funnel instrumented and optimized with data-driven pipeline management. Company benchmark: Amazon's Bar Raiser program gives independent interviewers veto power to protect hiring quality, and Google's structured hiring committees use calibrated rubrics to eliminate bias.",
    "rationale": "Anchor 1/2: Covers hiring mechanics (interview loops, bar raising, headcount justification, interviewer calibration, structured interviews, competitive hiring strategy, funnel optimization). Maps to C11-O1, C11-O2, C11-O7 through C11-O11."
  },
  {
    "anchorId": "C11-2",
    "capabilityId": "C11",
    "sourceTopic": "Onboarding Excellence & Talent Brand",
    "level1Developing": "Onboarding is informal — new hires figure it out. No engineering brand presence. Time-to-productivity not tracked. No referral pipeline.",
    "level2Emerging": "Basic onboarding documentation exists. Some buddy pairing. Beginning to track new hire experience. Occasional blog post or meetup participation.",
    "level3Competent": "Structured 30/60/90 onboarding with measurable milestones. Time-to-productivity tracked and improving. Buddy/mentor program formalized. Active blog or conference presence emerging. Referral pipeline maintained.",
    "level4Distinguished": "Onboarding continuously refined from new hire feedback. Time-to-productivity benchmarked against org. Engineering brand attracting inbound interest. Conference talks or open source contributing to senior talent pipeline.",
    "level5Advanced": "Time-to-productivity measured and optimized to org-best levels. Engineering brand is a recruiting advantage — candidates cite it in interviews. Conference talks and open source presence attract senior talent. Onboarding process is a model other teams adopt. Company benchmark: Meta's Bootcamp onboarding gets new engineers productive within 6 weeks through structured mentorship, and Google's engineering brand (publications, open source) drives inbound senior talent.",
    "rationale": "Anchor 2/2: Covers talent brand and onboarding (30/60/90 programs, time-to-productivity, engineering brand, referrals). Maps to C11-O3 through C11-O6. Intentionally separate from hiring mechanics — acquisition vs. integration are distinct sub-skills."
  },
  {
    "anchorId": "C12-1",
    "capabilityId": "C12",
    "sourceTopic": "Team Charter & Engineering Principles",
    "level1Developing": "Team culture exists by accident (whatever norms emerged). Recognition is sporadic. Inclusion is 'we treat everyone the same.'",
    "level2Emerging": "Starting to be intentional about team norms. Some recognition happening but not systematized. Awareness of inclusion beyond 'same treatment.' Beginning to document engineering practices.",
    "level3Competent": "Team charter written and referenced. Engineering principles documented and used in design reviews. Regular recognition rituals. Active inclusion practices (meeting facilitation, async options, equitable opportunity distribution). Explicit feedback channels ensuring every voice is heard. Cultural continuity maintained through growth and leadership transitions. Toxic behaviors addressed within 48 hours.",
    "level4Distinguished": "Team charter actively referenced and evolved. Engineering principles influencing decisions beyond own team. Recognition culture established and self-sustaining. Inclusive practices embedded and measurable in engagement surveys.",
    "level5Advanced": "Culture is intentional, measurable, and self-reinforcing. Engineering principles adopted beyond own team. Cultural continuity maintained through rapid growth and leadership transitions without degradation. Inclusive environment measurable in surveys and independently confirmed. Toxic behaviors caught and addressed proactively — no 'missing stair' dynamics. Candidates cite team culture as top-3 reason for accepting offer in post-hire surveys. Company benchmark: Netflix's Freedom and Responsibility culture doc is the canonical example of intentional culture at scale, and Spotify's explicit team Health Checks make culture measurable and discussable.",
    "rationale": "Anchor 1/2: Covers culture foundations (team charter, engineering principles, recognition, inclusion, cultural continuity, inclusive feedback channels, toxic behavior intervention). Maps to C12-O1, C12-O2, C12-O4 through C12-O8."
  },
  {
    "anchorId": "C12-2",
    "capabilityId": "C12",
    "sourceTopic": "Knowledge Sharing & Documentation Culture",
    "level1Developing": "Knowledge sharing is informal — tribal knowledge dominates. Documentation sparse and outdated. No structured forums for cross-team learning.",
    "level2Emerging": "Some documentation emerging but inconsistent. Occasional knowledge-sharing sessions. Beginning to notice that tribal knowledge creates bottlenecks and bus-factor risk.",
    "level3Competent": "Documentation standards maintained and enforced. Regular tech talks or knowledge-sharing rituals. Design doc culture established. Onboarding documentation reduces ramp time measurably.",
    "level4Distinguished": "Knowledge-sharing practices adopted by adjacent teams. Documentation culture self-reinforcing — team members contribute without prompting. Design doc quality consistently high. Cross-team learning forums thriving.",
    "level5Advanced": "Knowledge sharing institutionalized across org (tech talks, wikis, design doc culture). Documentation coverage comprehensive and maintained. Knowledge-sharing practices are a model other teams adopt. Reduces organizational bus-factor risk at scale. Company benchmark: Stripe's writing culture and Amazon's design doc requirements institutionalize knowledge sharing as an organizational practice, not an individual habit.",
    "rationale": "Anchor 2/2: Covers knowledge management (documentation, tech talks, design docs, cross-team learning). Maps to C12-O3. Intentionally separate from culture foundations — knowledge sharing is a distinct operational practice."
  },
  {
    "anchorId": "C13-1",
    "capabilityId": "C13",
    "sourceTopic": "Security Practices & Vulnerability Management",
    "level1Developing": "Ensures team follows security practices when reminded. Patches vulnerabilities reactively. Change management is informal. Compliance is handled last-minute before audits.",
    "level2Emerging": "Security practices becoming more consistent without reminders. Vulnerability patching improving but SLA sometimes missed. Change management process emerging. Starting to prepare for audits proactively.",
    "level3Competent": "Security embedded in development workflow (threat modeling, automated scanning, champion rotation). Security champions rotate quarterly and attend security guild. Automated security scanning integrated into CI/CD with severity-based deployment gates. Vulnerability SLAs met consistently (P0 <48hrs, P1 <7 days). Threat models required for features touching auth, payments, or PII. Tiered change management process in place.",
    "level4Distinguished": "Security embedded in development culture. Vulnerability SLAs consistently met without escalation. Change management influencing adjacent teams. Security champion rotation effective and producing results.",
    "level5Advanced": "Security culture driven across org. Change management standards adopted org-wide. Security champion program scaled beyond own team. Automated scanning and threat modeling are organizational standards. Teams proactively identify and mitigate security risks before they become vulnerabilities. Company benchmark: Google's BeyondCorp zero-trust model and Amazon's mandatory security review process demonstrate security as a proactive engineering discipline, not a compliance checkbox.",
    "rationale": "Anchor 1/2: Covers security operations (threat modeling, vulnerability management, change management, security champions, automated scanning, threat modeling for sensitive features). Maps to C13-O1 through C13-O3, C13-O5 through C13-O7."
  },
  {
    "anchorId": "C13-2",
    "capabilityId": "C13",
    "sourceTopic": "Compliance & Governance Automation",
    "level1Developing": "Compliance is handled last-minute before audits. Evidence collection is manual. Access controls inconsistent. No automated compliance checks.",
    "level2Emerging": "Beginning to embed compliance into workflows. Some automated scanning in place. Starting to track access control hygiene. Audit preparation moving earlier in the cycle.",
    "level3Competent": "Continuous compliance posture with automated evidence collection. Access governance automated (quarterly reviews, auto-expiring elevated permissions). Audit prep reduced from weeks to days.",
    "level4Distinguished": "Compliance automation reducing manual burden across the team. Audit readiness is continuous, not episodic. Governance practices influencing adjacent teams. Access governance producing clean audit results consistently.",
    "level5Advanced": "Zero P1/P2 findings in 3+ consecutive audit cycles. Compliance is a competitive advantage, not a burden. Governance automation is an org model. Continuous compliance frameworks adopted beyond own team. Company benchmark: Netflix automates compliance evidence collection continuously, making audit readiness a dashboard metric rather than a quarterly project.",
    "rationale": "Anchor 2/2: Covers compliance and governance (audit readiness, evidence collection, access governance, compliance automation). Maps to C13-O3, C13-O4. Intentionally separate from security operations — compliance is a distinct discipline from vulnerability management."
  },
  {
    "anchorId": "C14-1",
    "capabilityId": "C14",
    "sourceTopic": "Performance Reviews & Calibration",
    "level1Developing": "Writes reviews but they're vague. Calibration prep is last-minute. Avoids PIPs. Career conversations are infrequent.",
    "level2Emerging": "Reviews improving in specificity. Starting to prepare for calibration earlier. Beginning to address performance issues with HR guidance. Career conversations starting to happen regularly.",
    "level3Competent": "Evidence-based reviews with specific impact and rubric language. Continuous performance documentation — running notes updated weekly, not reconstructed at review time. Calibration cases prepared with cross-team comparison data. PIPs executed when needed with HR partnership. High performers managed with differentiated development plans and retention-conscious conversations. Managed exits executed with dignity and clear process. Quarterly career conversations for all reports.",
    "level4Distinguished": "Reviews consistently evidence-based and well-regarded. Calibration cases well-prepared with strong cross-team comparisons. Performance management handled professionally including difficult cases. Career conversations drive real development.",
    "level5Advanced": "Reviews set the standard for the org. Continuous performance documentation produces evidence-rich reviews with zero surprises. Calibration presence is authoritative and credible. High performer retention above 90% through differentiated investment. Performance management (including exits) handled cleanly — managed exits executed with dignity, full knowledge transfer, and zero legal escalations. Career development is the reason people join your team. Calibrates other EMs' performance standards. Company benchmark: Google's calibration committee model separates promotion decisions from direct managers, ensuring cross-team consistency and reducing individual bias in performance assessment.",
    "rationale": "Anchor 1/2: Covers performance operations (reviews, calibration, feedback, PIPs, continuous documentation, high performer management, managed exits). Maps to C14-O1 through C14-O4, C14-O6 through C14-O9."
  },
  {
    "anchorId": "C14-2",
    "capabilityId": "C14",
    "sourceTopic": "Promotion Readiness & Career Architecture",
    "level1Developing": "Promotion packets are reactive ('they've been doing this for a while'). No systematic approach to building promotion cases over time. Gap-filling stretch assignments not planned.",
    "level2Emerging": "Beginning to plan promotions 1-2 cycles ahead. Starting to identify and fill gaps through stretch assignments. Some awareness of what calibration committees look for.",
    "level3Competent": "Promo packets built over 2-3 cycles with deliberate gap-filling stretch assignments. Cross-team evidence gathering is systematic. Promotion cases well-structured with specific impact examples matching rubric criteria.",
    "level4Distinguished": "Multiple successful promotions per cycle demonstrate calibration skill. Promo packet quality recognized by calibration committees. Career development actively attracts talent to the team. Coaching other EMs on promotion readiness.",
    "level5Advanced": "Promotion track record is among the best in the org. Promo packet construction is a model others follow. Career architecture creates clear, achievable growth paths. Development reputation is a recruiting advantage. Company benchmark: Amazon's promotion process requires documented evidence of sustained next-level impact over multiple review cycles, and Google's promo committees evaluate packets independently of manager advocacy.",
    "rationale": "Anchor 2/2: Covers career growth architecture (promotion planning, stretch assignments, evidence building, career paths). Maps to C14-O5. Intentionally separate from performance operations — evaluation vs. development are distinct sub-skills."
  }
]
